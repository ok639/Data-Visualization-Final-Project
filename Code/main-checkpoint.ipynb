{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS : \n",
    "\n",
    "\n",
    "import time\n",
    "import re \n",
    "\n",
    "from functools import reduce\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import yfinance as yf \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import dash \n",
    "from dash import Dash \n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.exceptions import PreventUpdate\n",
    "from dash import dcc, html, dash_table, callback, callback_context, clientside_callback\n",
    "from dash import Input, Output, State, MATCH, ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you want to keep a main dataframe to store or update data\n",
    "main_df = pd.DataFrame()\n",
    "available_dates = main_df.index.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to record : Asset Classes & tickers within \n",
    "\n",
    "initializer = True \n",
    "\n",
    "dict_classes = {\n",
    "    'Equity' : [],\n",
    "    'Commodities' : [],\n",
    "    'Fixed Income' : [],\n",
    "    'Forex' : [],\n",
    "}\n",
    "\n",
    "dict_sectors = {\n",
    "    'Financials' : [],\n",
    "    'Technology' : [],\n",
    "    'Industrial' : [],\n",
    "    'Consumer' : [],\n",
    "    'Utilities' : [],\n",
    "    'Other' : []\n",
    "}\n",
    "\n",
    "dict_commo = {\n",
    "    'Agriculture' : [],\n",
    "    'Precious Metals' : [],\n",
    "    'Energy' : [],\n",
    "    'Industrials' : []\n",
    "}\n",
    "\n",
    "list_tickers = ['AAPL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAGE 1 : HOME \n",
    "\n",
    "def reset_global_vars():\n",
    "    global initializer, dict_classes, dict_sectors, dict_commo, list_tickers\n",
    "    \n",
    "    initializer = True \n",
    "    \n",
    "    dict_classes = {\n",
    "    'Equity' : [],\n",
    "    'Commodities' : [],\n",
    "    'Fixed Income' : [],\n",
    "    'Forex' : [],\n",
    "    }\n",
    "\n",
    "    dict_sectors = {\n",
    "        'Financials' : [],\n",
    "        'Technology' : [],\n",
    "        'Industrial' : [],\n",
    "        'Consumer' : [],\n",
    "        'Utilities' : [],\n",
    "        'Other' : []\n",
    "    }\n",
    "\n",
    "    dict_commo = {\n",
    "        'Agriculture' : [],\n",
    "        'Precious Metals' : [],\n",
    "        'Energy' : [],\n",
    "        'Industrials' : []\n",
    "    }\n",
    "\n",
    "    list_tickers = []\n",
    "    \n",
    "def scaled_df(df):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=df.columns, index=df.index)\n",
    "\n",
    "    return scaled_df\n",
    "\n",
    "\n",
    "def get_logreturn(df_price_col):\n",
    "    return np.log(df_price_col / df_price_col.shift(1)) * 100 \n",
    "\n",
    "\n",
    "def minmax_scaler(df, spread = 1):\n",
    "    min_df = df.min()\n",
    "    max_df = df.max() \n",
    "    \n",
    "    df = df.apply(lambda x : ((x-min_df) / (max_df - min_df)) / spread)\n",
    "    \n",
    "    return df \n",
    "\n",
    "\n",
    "def data_loader(ticker_name, start, end, interval='1d'):\n",
    "    ticker = ticker_name \n",
    "    try : \n",
    "        df = yf.download(ticker, start=start, end=end)\n",
    "        \n",
    "    \n",
    "        if len(df) != 0: \n",
    "            date_column = df.index\n",
    "            df = df.sort_index()\n",
    "\n",
    "            #Daily price normalized to the total volume of the dataset\n",
    "            df['price_volume'] = df['Adj Close'] * df['Volume']\n",
    "            df['Norm_PV'] = (df['price_volume'] / df['Volume'].sum()) #Norm_PV = Normalized Price Volume\n",
    "\n",
    "            #Renaming (for merging purposes):\n",
    "            title_1 = ticker + ': Adj Close'\n",
    "            title_2 = ticker + ': Norm_PV'\n",
    "            title_3 = ticker + ': Log-Returns'\n",
    "\n",
    "            #Log-returns\n",
    "            df[title_3] = get_logreturn(df['Adj Close']) #Results are in %\n",
    "            df.drop(columns = ['Open', 'High', 'Low', 'Adj Close', 'Volume', 'price_volume'], axis = 1, inplace = True)\n",
    "\n",
    "            df.rename(columns={'Close': title_1,\n",
    "                                    'Norm_PV': title_2,\n",
    "                                   }, inplace=True)\n",
    "            pd.to_datetime(df.index, format='%Y-%m-%d')\n",
    "\n",
    "        return df \n",
    "    \n",
    "    except Exception as e: \n",
    "        return e\n",
    "\n",
    "\n",
    "\n",
    "def data_loader_format_all(ticker, start, end, interval='1d'):\n",
    "    global main_df, list_tickers\n",
    "    \n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    temp = list_tickers \n",
    "    temp.append(ticker)\n",
    "    temp = set(temp)\n",
    "    \n",
    "    for i, tick in enumerate(temp):             \n",
    "        if i == 0: \n",
    "            main_df = data_loader(tick, start, end)\n",
    "            continue\n",
    "        df = data_loader(tick, start, end)\n",
    "        main_df = pd.merge(main_df, df, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "    return \"All ticker frames updated.\" \n",
    "\n",
    "\n",
    "def curve_plotter(df, mode='price', scaled=False):\n",
    "    global list_tickers \n",
    "    if mode == 'return':\n",
    "        scaled=False\n",
    "        suffix='Returns'\n",
    "    else: \n",
    "        suffix='Adj Close'\n",
    "        \n",
    "    matching_columns = [col for col in df.columns if col.endswith(suffix)]\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "    df.drop(matching_columns, axis=1, inplace=True)  \n",
    "    \n",
    "    \n",
    "def prepare_and_scale_df(df1, df2, key, scale):\n",
    "    if key == 0:\n",
    "        col_list = list(df1.columns)\n",
    "        adj_close_list = [item for item in col_list if \"Adj Close\" in item]\n",
    "        sub_df = df1[adj_close_list]\n",
    "        sub_df.columns = [re.sub(r'^\\s+|\\s+$', '', col.split(\":\")[0]) for col in adj_close_list]\n",
    "    else:\n",
    "        col_list = list(df2.columns)\n",
    "        adj_close_list = [item for item in col_list if \"Adj Close\" in item]\n",
    "        sub_df = df2[adj_close_list]\n",
    "        sub_df.columns = [re.sub(r'^\\s+|\\s+$', '', col.split(\":\")[0]) for col in adj_close_list]\n",
    "\n",
    "    if scale and not sub_df.empty:\n",
    "        sub_df = scaled_df(sub_df)\n",
    "    \n",
    "    return sub_df\n",
    "\n",
    "\n",
    "def plot_fig(df):\n",
    "    fig = go.Figure()\n",
    "    for ticker in df.columns:\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=df[ticker], mode='lines', name=ticker))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Adjusted Close Prices Over Time for selected tickers',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Adjusted Close Price',\n",
    "        legend_title=\"Ticker\"\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAGE 2 : ANALYTICS \n",
    "\n",
    "\n",
    "def relative_change(corr1, corr2):\n",
    "    range_corr = 2\n",
    "    rel_range_change = ((corr2 - corr1) / range_corr) * 100\n",
    "    \n",
    "    return rel_range_change        \n",
    "\n",
    "\n",
    "\n",
    "def rolling_corr(df, ref_date, span):\n",
    "    try:\n",
    "        position = df.index.get_loc(ref_date) + 1\n",
    "        start_position = position - span\n",
    "        filtered_df = df.iloc[start_position:position]\n",
    "        corr_matrix = filtered_df.corr()\n",
    "\n",
    "        return corr_matrix.round(2)\n",
    "\n",
    "    except KeyError as err: \n",
    "        print(f'Error due to wrong date/span input: {err}, Date : {ref_date}, Span : {span}.')\n",
    "        print(f'Recall date range of input dataframe: {df.index[0], df.index[-1]}')\n",
    "\n",
    "    \n",
    "\n",
    "def matrix_difference(matrix1, matrix2):\n",
    "    # Check if the matrices have the same shape\n",
    "    if matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "    \n",
    "    # Initialize an empty matrix to store the differences\n",
    "    rows = matrix1.shape[0]\n",
    "    columns = matrix1.shape[1]\n",
    "    result_matrix = pd.DataFrame(np.zeros((rows, columns)))\n",
    "    result_matrix.columns = list_tickers\n",
    "    \n",
    "    # Iterate through the rows and columns of the matrices\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            perct_change = relative_change(matrix1.iloc[i, j], matrix2.iloc[i, j])\n",
    "            result_matrix.iloc[i, j] = perct_change       \n",
    "    return result_matrix\n",
    "\n",
    "\n",
    "\n",
    "def matrix_difference_qual(matrix1, matrix2, heatmap=True):\n",
    "    category_map = None\n",
    "\n",
    "    # Check if the matrices have the same shape\n",
    "    if matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "    \n",
    "    # Initialize an empty matrix to store the differences\n",
    "    rows = matrix1.shape[0]\n",
    "    columns = matrix1.shape[1]\n",
    "    result_matrix = pd.DataFrame(np.zeros((rows, columns)))\n",
    "    result_matrix.columns = list_tickers\n",
    "    \n",
    "    # Iterate through the rows and columns of the matrices\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            # Perform differentiation based on the values of the elements\n",
    "            \n",
    "            if matrix1.iloc[i, j] == 0 or matrix2.iloc[i, j] == 0:\n",
    "                if matrix1.iloc[i, j] < 0:\n",
    "                    matrix2.iloc[i,j] = -0.00001\n",
    "                elif matrix1.iloc[i,j] > 0: \n",
    "                    matrix2.iloc[i,j] = 0.00001\n",
    "                elif matrix2.iloc[i,j] < 0: \n",
    "                    matrix1.iloc[i,j] = 0.00001\n",
    "                elif matrix2.iloc[i,j] > 0: \n",
    "                    matrix1.iloc[i,j] = -0.00001\n",
    "                    \n",
    "            if matrix1.iloc[i, j] < 0 and matrix2.iloc[i, j] < 0:\n",
    "                if matrix2.iloc[i, j] > matrix1.iloc[i, j]:\n",
    "                    result_matrix.iloc[i, j] = 'Neg Stronger'\n",
    "                else:\n",
    "                    result_matrix.iloc[i, j] = 'Neg Weaker'\n",
    "            elif matrix1.iloc[i, j] > 0 and matrix2.iloc[i, j] > 0:\n",
    "                if matrix2.iloc[i, j] > matrix1.iloc[i, j]:\n",
    "                    result_matrix.iloc[i, j] = 'Pos Stronger'\n",
    "                else:\n",
    "                    result_matrix.iloc[i, j] = 'Pos Weaker'\n",
    "            elif matrix1.iloc[i, j] > 0 and matrix2.iloc[i, j] < 0:\n",
    "                result_matrix.iloc[i, j] = 'Neg Stronger'\n",
    "            elif matrix1.iloc[i, j] < 0 and matrix2.iloc[i, j] > 0:\n",
    "                result_matrix.iloc[i, j] = 'Pos Stronger'\n",
    "            elif 0.95 <= matrix1.iloc[i, j] / matrix2.iloc[i, j] <= 1.05:\n",
    "                result_matrix.iloc[i, j] = 'UNCH'\n",
    "            else: \n",
    "                print(matrix1.iloc[i, j], matrix2.iloc[i,j])\n",
    "                print(list_tickers[i], list_tickers[j])\n",
    "                \n",
    "    if heatmap: \n",
    "        category_map = {'Neg Stronger': -10, 'Neg Weaker': -5, \n",
    "                        'Pos Stronger': 10, 'Pos Weaker': 5, \n",
    "                        'UNCH': 0}\n",
    "        df_numeric = result_matrix.applymap(lambda x: category_map[x])\n",
    "        df_numeric.index = list_tickers\n",
    "        \n",
    "        return df_numeric\n",
    "\n",
    "    else: \n",
    "        print(\"Can't return a heatmap - Categ Variables of String Type\")\n",
    "        return result_matrix\n",
    "\n",
    "    \n",
    "\n",
    "def rolling_corr_difference(df, ref_date, span):\n",
    "    \n",
    "    # Calculate correlation matrix for the current span\n",
    "    corr_matrix_current = rolling_corr(df, ref_date, span)\n",
    "    \n",
    "    # Get the previous corr matrix's ref_date\n",
    "    index_position = df.index.get_loc(ref_date)\n",
    "    \n",
    "    # Previous corr matrix's ref index position is max(0, index_position - span)\n",
    "    temp_index_position = index_position - span \n",
    "    if temp_index_position < 0: \n",
    "        print(f'Period for Previous Corr Matrix calculation out of bound. Setting reference date to {df.index[0]}')\n",
    "        span = index_position\n",
    "\n",
    "    new_index_position = df.index.get_loc(df.index[temp_index_position])\n",
    "    new_ref_date = df.index[new_index_position]\n",
    "\n",
    "    # Calculate correlation matrix for the previous span\n",
    "    corr_matrix_prev = rolling_corr(df, new_ref_date, span)\n",
    "    \n",
    "    # Calculate the difference between correlation matrices\n",
    "    corr_diff = matrix_difference(corr_matrix_prev, corr_matrix_current)\n",
    "    corr_diff_qual = matrix_difference_qual(corr_matrix_prev, corr_matrix_current)\n",
    "    \n",
    "    column_names = df.columns.tolist()\n",
    "    \n",
    "    #MASKING FOR HALF HEAT MAPs\n",
    "    mask = np.triu(np.ones_like(corr_diff, dtype=bool))\n",
    "    corr_diff_masked = np.where(mask, None, corr_diff)  # Replace upper triangular part with None\n",
    "    \n",
    "    mask_qual = np.triu(np.ones_like(corr_diff_qual, dtype=bool))\n",
    "    corr_diff_qual_masked = np.where(mask_qual, None, corr_diff_qual)  # Replace upper triangular part with None\n",
    "\n",
    "    \n",
    "    # Plotting heatmap for relative range percentage change\n",
    "    fig_relative = go.Figure(data=go.Heatmap(z=corr_diff_masked, colorscale='RdYlGn',\n",
    "                                             x=column_names, y=column_names))\n",
    "    fig_relative.update_layout(title=f'Relative Range Percentage Change of Rolling Correlations between Assets Log Returns, {span} freq periods.',\n",
    "                               xaxis_title='Assets', yaxis_title='Assets',                           \n",
    "                               plot_bgcolor='white',  paper_bgcolor='white')\n",
    "\n",
    "    # Assuming `corr_diff_qual` is plotted here instead\n",
    "    fig_directional = go.Figure(data=go.Heatmap(z=corr_diff_qual_masked, colorscale='bluered',\n",
    "                                                x=column_names, y=column_names))\n",
    "    fig_directional.update_layout(title=f'Directional Difference between Rolling Correlation Matrices of Assets Log Returns, {span} freq periods.',\n",
    "                                  xaxis_title='Assets', yaxis_title='Assets',\n",
    "                                  plot_bgcolor='white',  paper_bgcolor='white')\n",
    "    # Customizing the colorbar tick labels\n",
    "    fig_directional.update_traces(colorbar_tickvals=[-10, -5, 0, 5, 10],\n",
    "                  colorbar_ticktext=['Negative Stronger', 'Negative Weaker', 'UNCH', 'Positive Weaker', 'Positive Stronger'])\n",
    "    \n",
    "    fig_relative.update_layout(\n",
    "    width=900,  # Adjust width\n",
    "    height=900,  # Adjust height\n",
    "    title=f'Relative Range Percentage Change of Rolling Correlations between Assets Log Returns, {span} freq periods.',\n",
    "    xaxis_title='Assets',\n",
    "    yaxis_title='Assets',\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white',\n",
    "    xaxis={'autorange': True, 'tickangle': 45},  # Rotate x-axis labels to prevent overlap\n",
    "    yaxis={'autorange': True}\n",
    "    )\n",
    "\n",
    "    fig_directional.update_layout(\n",
    "        width=900,  # Adjust width\n",
    "        height=900,  # Adjust height\n",
    "        title=f'Directional Difference between Rolling Correlation Matrices of Assets Log Returns, {span} freq periods.',\n",
    "        xaxis_title='Assets',\n",
    "        yaxis_title='Assets',\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        xaxis={'autorange': True, 'tickangle': 45},  # Rotate x-axis labels to prevent overlap\n",
    "        yaxis={'autorange': True}\n",
    "    )\n",
    "    return fig_relative, fig_directional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_net(df, ref_date, corr_threshold, span):\n",
    "    global dict_classes\n",
    "    corr_matrix = rolling_corr(df, ref_date, span)\n",
    "    \n",
    "    # Initialize the graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Ticker categories and their colors\n",
    "    ticker_categs = dict_classes\n",
    "    \n",
    "    colors = {\n",
    "        'Equity': 'yellow',\n",
    "        'Index': 'blue',\n",
    "        'Fixed Income': 'red',\n",
    "        'Commodities': 'orange',\n",
    "        'Crypto': 'green'\n",
    "    }\n",
    "    \n",
    "    # Node colors based on their category\n",
    "    node_colors = {}\n",
    "    for category, nodes in ticker_categs.items():\n",
    "        for node in nodes:\n",
    "            node_colors[node] = colors[category]\n",
    "    \n",
    "    # Determine which nodes should be included based on the correlation threshold\n",
    "    nodes_to_include = set()\n",
    "    for i in corr_matrix.columns:\n",
    "        for j in corr_matrix.columns:\n",
    "            if i != j and abs(corr_matrix.loc[i, j]) > corr_threshold:\n",
    "                nodes_to_include.add(i)\n",
    "                nodes_to_include.add(j)\n",
    "    \n",
    "    # Only add nodes that are part of an edge meeting the threshold\n",
    "    for node in nodes_to_include:\n",
    "        G.add_node(node, color=node_colors.get(node, 'grey'))\n",
    "    \n",
    "    # Add edges to the graph based on correlation\n",
    "    for i in corr_matrix.columns:\n",
    "        for j in corr_matrix.columns:\n",
    "            if i != j:  # Ensure we don't compare the same stock to itself\n",
    "                corr = corr_matrix.loc[i, j]\n",
    "                if abs(corr) > corr_threshold:  # Check if the correlation meets the threshold\n",
    "                    # Add an edge with color based on the sign of the correlation\n",
    "                    G.add_edge(i, j, weight=corr, color='green' if corr > 0 else 'red')\n",
    "\n",
    "    # Assuming 'G' is your original graph with 'weight' attributes holding the correlations\n",
    "    H = G.copy()\n",
    "\n",
    "    # Update edge weights in H to be absolute values of the original weights\n",
    "    for u, v, d in H.edges(data=True):\n",
    "        d['weight'] = abs(d['weight'])\n",
    "\n",
    "\n",
    "    # Assuming H is your graph for layout and G contains original correlation weights\n",
    "    pos = nx.kamada_kawai_layout(H)                    \n",
    "    \n",
    "\n",
    "    # Initialize the figure once, before the loop\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # For edges, create individual traces within the loop\n",
    "    for edge in G.edges(data=True):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        corr_value = edge[2]['weight']\n",
    "\n",
    "        # Determine the color based on the correlation value\n",
    "        edge_color = 'green' if corr_value > 0 else 'red'\n",
    "\n",
    "        # Create an individual trace for this edge\n",
    "        edge_trace = go.Scatter(\n",
    "            x=[x0, x1, None], \n",
    "            y=[y0, y1, None],\n",
    "            line=dict(width=0.5, color=edge_color),\n",
    "            mode='lines',\n",
    "            hoverinfo='none',\n",
    "            showlegend=False# No hover info for the line itself\n",
    "        )\n",
    "        fig.add_trace(edge_trace)\n",
    "\n",
    "        # Invisible marker at the midpoint for hover text\n",
    "        midpoint_trace = go.Scatter(\n",
    "            x=[(x0 + x1) / 2],\n",
    "            y=[(y0 + y1) / 2],\n",
    "            text=[f'{edge[0]}-{edge[1]}: {corr_value:.2f}'],\n",
    "            mode='markers',\n",
    "            hoverinfo='text',\n",
    "            marker=dict(size=0.1, color='rgba(0,0,0,0)'),  # Make the marker virtually invisible\n",
    "            showlegend=False\n",
    "        )\n",
    "        fig.add_trace(midpoint_trace)\n",
    "\n",
    "        \n",
    "    # Track which categories have been added to the legend\n",
    "    added_categories = set()\n",
    "    for node in G.nodes():\n",
    "        x, y = pos[node]\n",
    "        category = None\n",
    "        for categ, members in ticker_categs.items():\n",
    "            if node in members:\n",
    "                category = categ\n",
    "                break\n",
    "        if category and category not in added_categories:\n",
    "            # Add a representative node for this category to the legend\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[x], y=[y],\n",
    "                mode='markers+text',\n",
    "                marker=dict(color=colors[category], size=10),\n",
    "                name=category,  # This sets the legend entry,\n",
    "                hoverinfo='none'\n",
    "            ))\n",
    "            added_categories.add(category)\n",
    "\n",
    "    # Add node trace after all edge traces have been added\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    node_marker_colors = []\n",
    "\n",
    "    for node in G.nodes():\n",
    "        x, y = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        node_text.append(node)\n",
    "        node_marker_colors.append(G.nodes[node]['color'])\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x, y=node_y, text=node_text, mode='markers+text', hoverinfo='none',\n",
    "        marker=dict(showscale=False, color=node_marker_colors, size=20, line_width=2),\n",
    "        textposition=\"bottom center\", showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.add_trace(node_trace)\n",
    "\n",
    "    # Set the layout for the figure\n",
    "    fig.update_layout(\n",
    "        showlegend=True,\n",
    "        hovermode='closest',\n",
    "        margin=dict(b=0,l=0,r=0,t=0),\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        legend_title_text='Node Categories',\n",
    "        legend=dict(x=1, y=0, xanchor='right', yanchor='bottom')\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APP LAYOUT SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "external_stylesheets = [dbc.themes.BOOTSTRAP]\n",
    "\n",
    "app = Dash(__name__,\n",
    "           external_stylesheets=external_stylesheets,\n",
    "           suppress_callback_exceptions=True,  \n",
    "           prevent_initial_callbacks=True) \n",
    "\n",
    "\n",
    "#Creating navigation bar : \n",
    "navbar = dbc.NavbarSimple(\n",
    "    children=[\n",
    "        dbc.NavItem(dbc.NavLink(\"Home\", href=\"/\")),\n",
    "        dbc.NavItem(dbc.NavLink(\"Analytics\", href=\"/analytics\")),\n",
    "        dbc.NavItem(dbc.NavLink(\"Portfolio\", href=\"/portfolio\")),\n",
    "    ],\n",
    "    brand=\"Demo App\",\n",
    "    brand_href=\"/\",\n",
    "    color=\"primary\",\n",
    "    dark=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Define the app layout with different pages\n",
    "app.layout = html.Div([\n",
    "    dcc.Store(id='session-data'),\n",
    "    dcc.Location(id='url'),\n",
    "    navbar,\n",
    "    html.Div(id='page-content'), \n",
    "])\n",
    "\n",
    "@app.callback(Output('page-content', 'children'),\n",
    "              [Input('url', 'pathname')])\n",
    "def display_page(pathname):\n",
    "    if pathname == '/analytics':\n",
    "        return layout_analytics\n",
    "    elif pathname == '/portfolio':\n",
    "#         return create_portfolio_layout()\n",
    "        return layout_portfolio\n",
    "    elif pathname == '/':\n",
    "        return layout_home\n",
    "    else:\n",
    "        return html.Div([\n",
    "            html.H1('404 Error'),\n",
    "            html.P('Page not found: the pathname was {}'.format(pathname))\n",
    "        ], style={'textAlign': 'center'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAYOUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dash import dcc, html\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "layout_home = html.Div([\n",
    "    dcc.Store(id='storage'),\n",
    "    dbc.Container([\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div([\n",
    "                html.H3(\"Enter Stock Ticker:\", style={'textAlign': 'center'}),\n",
    "                dbc.Input(id='ticker-input', placeholder='Enter ticker, e.g., AAPL', type='text', value='AAPL', style={'margin': '30px 0'})\n",
    "            ], style={'backgroundColor': 'white', 'padding': '10px', 'borderRadius': '5px', 'boxShadow': '0 4px 8px 0 rgba(0, 0, 0, 0.2)'}), width=12)\n",
    "        ], justify='center', className=\"mb-4\", style={'paddingTop': '10px'}),\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col(\n",
    "                dcc.Dropdown(\n",
    "                    id='asset-class-dropdown',\n",
    "                    options=[\n",
    "                        {'label': 'Equity', 'value': 'Equity'},\n",
    "                        {'label': 'Forex', 'value': 'Forex'},\n",
    "                        {'label': 'Fixed Income', 'value': 'Fixed Income'},\n",
    "                        {'label': 'Commodities', 'value': 'Commodities'}\n",
    "                    ],\n",
    "                    placeholder=\"Select asset class\", value=\"Equity\"), width=4),\n",
    "            dbc.Col(\n",
    "                dbc.Input(id='start-date-input', placeholder='Start Date (YYYY-MM-DD)', type='text', value='2020-12-31'), width=4),\n",
    "            dbc.Col(\n",
    "                dbc.Input(id='end-date-input', placeholder='End Date (YYYY-MM-DD)', type='text', value='2023-12-31'), width=4)\n",
    "        ], justify='center', className=\"mb-4\"),  # Added comma here\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Checkbox(id='scale-checkbox', className='form-check-input'),\n",
    "                html.Label('Scaled', htmlFor='scale-checkbox', className='form-check-label', style={'margin-left': '10px'})\n",
    "            ], width=3, align='start'),\n",
    "            dbc.Col(dbc.Button('Download Data', id='submit-button', color='danger', n_clicks=0, className='btn-lg'), width=3, align='center'),\n",
    "            dbc.Col(dbc.Button('Reset Data', id='reset-button', color='primary', n_clicks=0, className='btn-lg'), width=3, align='end')\n",
    "        ], justify='center', className=\"mb-3\"),  # Added comma here\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div(id='output-container', style={'color': 'white'}), width=12)\n",
    "        ], justify='center', className=\"mb-3\")\n",
    "    ], style={'height': '100vh', 'backgroundColor': '#000000', 'color': 'white'})\n",
    "], style={'backgroundColor': '#000000'})\n",
    "\n",
    "\n",
    "# clientside_callback(\n",
    "#     \"\"\"\n",
    "#     function(n_clicks, start_date, end_date) {\n",
    "#         if(n_clicks > 0) {\n",
    "#             sessionStorage.setItem('start_date', start_date);\n",
    "#             sessionStorage.setItem('end_date', end_date);\n",
    "#         }\n",
    "#     }\n",
    "#     \"\"\",\n",
    "#     Output('url', 'pathname'),  # Navigate or refresh the page as needed\n",
    "#     [Input('save-dates-btn', 'n_clicks')],\n",
    "#     [State('start-date-input', 'date'), State('end-date-input', 'date')]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import dcc, html\n",
    "\n",
    "layout_analytics = html.Div([\n",
    "    html.H1(\"Directional Momentum Visualization\", style={'textAlign': 'center'}),\n",
    "    html.H2(\"Network Graph Visualization\", style={'textAlign': 'center'}),\n",
    "    dcc.Store(id='store-corr-threshold', storage_type='session'),  # Store for correlation threshold\n",
    "    dcc.Store(id='store-span', storage_type='session'),  # Store for span\n",
    "    dcc.Store(id='store-selected-date', storage_type='session'),  # Store for selected date\n",
    "    dcc.Store(id='net-graph', storage_type='session'),\n",
    "    dcc.Store(id='heatmap-relative', storage_type='session'),\n",
    "    dcc.Store(id='heatmap-directional', storage_type='session'),\n",
    "\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label(\"Correlation Threshold\", style={'textAlign': 'center'}),\n",
    "            dcc.Slider(\n",
    "                id='corr-threshold-slider',\n",
    "                min=0,\n",
    "                max=1,\n",
    "                step=0.01,\n",
    "                value=0.5,  # Default value\n",
    "                marks={str(i/10): str(i / 10) for i in range(0, 11)}, \n",
    "            )\n",
    "        ], style={'width': '30%', 'display': 'inline-block', 'padding': '20px'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Span\", style={'textAlign': 'center'}),\n",
    "            dcc.Input(\n",
    "                id='span-input',\n",
    "                type='number',\n",
    "                value=5,  \n",
    "                min=1,  \n",
    "                max=100,  \n",
    "                step=1  \n",
    "            )\n",
    "        ], style={'width': '15%', 'display': 'inline-block', 'padding': '20px'}),\n",
    "\n",
    "        html.Div([\n",
    "            dcc.DatePickerSingle(\n",
    "                id='date-picker',\n",
    "                min_date_allowed='start',\n",
    "                max_date_allowed='end',\n",
    "                initial_visible_month='start',\n",
    "                date=str('start')  # Set initial date\n",
    "            )\n",
    "        ], style={'width': '30%', 'display': 'inline-block', 'textAlign': 'right', 'float': 'right', 'padding': '20px'}),\n",
    "    ], style={'display': 'flex', 'justifyContent': 'space-between'}),\n",
    "    \n",
    "\n",
    "    dcc.Graph(id='network-graph'),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.H2(\"Heatmap, Relative\", style={'textAlign': 'center'}),\n",
    "            dcc.Graph(id='heatmap-relative'),\n",
    "        ], style={'width': '50%', 'display': 'inline-block'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.H2(\"Heatmap, Directional\", style={'textAlign': 'center'}),\n",
    "            dcc.Graph(id='heatmap-directional'),\n",
    "        ], style={'width': '50%', 'display': 'inline-block'}),\n",
    "    ], style={'display': 'flex'}),  # This container will hold both heatmaps side by side\n",
    "    \n",
    "    html.Div(id='error-message', style={'color': 'red', 'fontWeight': 'bold'})  # Error message div\n",
    "], style={'padding': '20px'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### WE WANT A DYNAMIC LAYOUT , SO : \n",
    "\n",
    "# def create_portfolio_layout():\n",
    "#     return html.Div([\n",
    "#         html.H2(\"Build Your Portfolio\"),\n",
    "#         html.Div(id='weight-error-message', style={'color': 'red'}),  \n",
    "#         html.Div([\n",
    "#             dbc.InputGroup(\n",
    "#                 [dbc.InputGroupText(ticker), dbc.Input(type=\"number\", min=0, max=100, step=1, id=f'input-{ticker}')],\n",
    "#                 className='mb-3'\n",
    "#             ) for ticker in list_tickers\n",
    "#         ]),\n",
    "#         dcc.DatePickerSingle(\n",
    "#             id='start-date-picker',\n",
    "#             min_date_allowed='start',\n",
    "#             max_date_allowed='end',\n",
    "#             initial_visible_month='start',\n",
    "#             date='start',\n",
    "#             display_format='YYYY-MM-DD'\n",
    "#         ),\n",
    "#         dcc.DatePickerSingle(\n",
    "#             id='end-date-picker',\n",
    "#             min_date_allowed='start',\n",
    "#             max_date_allowed='end',\n",
    "#             initial_visible_month='end',\n",
    "#             date='end',\n",
    "#             display_format='YYYY-MM-DD'\n",
    "#         ),\n",
    "#         dcc.Interval(id='page-load-trigger', interval=1, max_intervals=1),  # Trigger once on load\n",
    "#         dbc.Button(\"Calculate Portfolio\", id='calculate-portfolio-btn', n_clicks=0),\n",
    "#         dcc.Graph(id='portfolio-performance-graph')\n",
    "#     ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from dash import ClientsideFunction \n",
    "\n",
    "# app.clientside_callback(\n",
    "#     ClientsideFunction(\n",
    "#         namespace='clientside',\n",
    "#         function_name='load_dates'\n",
    "#     ),\n",
    "#     output=[\n",
    "#         Output('start-date-picker', 'min_date_allowed'),\n",
    "#         Output('start-date-picker', 'max_date_allowed'),\n",
    "#         Output('start-date-picker', 'initial_visible_month'),\n",
    "#         Output('start-date-picker', 'date'),\n",
    "#         Output('end-date-picker', 'min_date_allowed'),\n",
    "#         Output('end-date-picker', 'max_date_allowed'),\n",
    "#         Output('end-date-picker', 'initial_visible_month'),\n",
    "#         Output('end-date-picker', 'date')\n",
    "#     ],\n",
    "#     inputs=[Input('page-load-trigger', 'n_intervals')]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_portfolio = html.Div([\n",
    "    dcc.Location(id='url'),\n",
    "    dcc.Store(id='ticker-list'),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.DatePickerSingle(\n",
    "                id='portfolio-date-picker',\n",
    "                display_format='YYYY-MM-DD'\n",
    "            ),\n",
    "            html.Button(\"Reset All\", id=\"reset-button\", className=\"btn btn-warning\", style={'margin-top': '10px'}),  # Reset button next to DatePicker\n",
    "        ], width=4),\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='ticker-dropdown',\n",
    "                options=[],  # dynamically generated options from list_ticker (global var)\n",
    "                multi=False\n",
    "            ),\n",
    "            html.Button(\"Confirm Weight\", id=\"confirm-weight-btn\"),\n",
    "            dcc.Slider(\n",
    "                id='weight-slider',\n",
    "                min=0,\n",
    "                max=100,\n",
    "                step=1,\n",
    "                value=0,\n",
    "                marks={i: str(i) for i in range(0, 101, 10)}\n",
    "            ),\n",
    "            html.Div(id='remaining-weight', children='Remaining Weight: 100', style={'margin-top': '20px'})\n",
    "        ], width=8)\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='portfolio-performance-graph'),  # Line chart for portfolio performance\n",
    "        ], width=6),\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='stock-performance-viz'),  # Bar chart for stock performance\n",
    "        ], width=6)\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dash_table.DataTable(\n",
    "                id='weights-table',\n",
    "                columns=[\n",
    "                    {'name': 'Ticker', 'id': 'ticker'},\n",
    "                    {'name': 'Weight', 'id': 'weight'}\n",
    "                ],\n",
    "                data=[]\n",
    "            )\n",
    "        ])\n",
    "    ]),\n",
    "    html.Button(\"Launch Portfolio Analysis\", id=\"launch-analysis-btn\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALLBACKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.callback(\n",
    "#     Output('storage-data', 'data'),\n",
    "#     [Input('start-date-input', 'value'),\n",
    "#      Input('end-date-input', 'value'),\n",
    "#      Input('scale-checkbox', 'value')],\n",
    "#     prevent_initial_call=True\n",
    "# )\n",
    "# def store_date_and_scale(start_date, end_date, scale):\n",
    "#     return {'start': start_date, 'end': end_date, 'scale': scale}\n",
    "\n",
    "# @app.callback(\n",
    "#     [Output('start-date-input', 'value'),\n",
    "#      Output('end-date-input', 'value'),\n",
    "#      Output('scale-checkbox', 'value')],\n",
    "#     [Input('storage-data', 'data')],\n",
    "#     prevent_initial_call=True\n",
    "# )\n",
    "# def load_date_and_scale(storage_data):\n",
    "#     if storage_data is None:\n",
    "#         raise exceptions.PreventUpdate\n",
    "#     return storage_data.get('start'), storage_data.get('end'), storage_data.get('scale')\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [Output('output-container', 'children'),\n",
    "     Output('session-data', 'data')],\n",
    "    [Input('submit-button', 'n_clicks'),\n",
    "     Input('reset-button', 'n_clicks'),\n",
    "     Input('scale-checkbox', 'value'),\n",
    "     Input('session-data', 'data')],\n",
    "    [State('ticker-input', 'value'),\n",
    "     State('asset-class-dropdown', 'value'),\n",
    "#      State('sector-dropdown', 'value'),\n",
    "     State('start-date-input', 'value'),\n",
    "     State('end-date-input', 'value')]\n",
    ")\n",
    "def update_or_reload_data(submit_n_clicks, reset_n_clicks, scale, session_data,\n",
    "                          ticker, asset_class, start_date, end_date):\n",
    "    global main_df\n",
    "    global initializer\n",
    "    global list_tickers, dict_classes, dict_sectors, dict_commo\n",
    "    key = 0\n",
    "    triggered_id = callback_context.triggered[0]['prop_id'].split('.')[0]\n",
    "    \n",
    "    json_dump = None\n",
    "    \n",
    "    start_time = dt.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    end_time = dt.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "    if initializer:\n",
    "        initializer = False\n",
    "        return html.Div(\"Empty Graph Data\"), {'Price Plot' : None, 'start' : None, 'end' : None}\n",
    "    \n",
    "    if triggered_id == 'reset-button' and reset_n_clicks > 0:\n",
    "        main_df = pd.DataFrame()\n",
    "        reset_global_vars()\n",
    "        return html.Div(\"Data has been reset\"), {'Price Plot' : None, 'start' : None, 'end' : None}\n",
    "\n",
    "    \n",
    "    if triggered_id == 'submit-button' or triggered_id == 'scale-checkbox':\n",
    "        try:\n",
    "            df = data_loader(ticker, start=start_date, end=end_date)\n",
    "            df.dropna(inplace=True)\n",
    "            if df.empty:\n",
    "                return html.Div(\"No data available for the selected ticker and date range.\"), {'Price Plot' : None, 'start' : None, 'end' : None}\n",
    "\n",
    "            if main_df.empty:\n",
    "                main_df = df\n",
    "            else:\n",
    "                prefix = ticker\n",
    "                matching_columns = [col for col in main_df.columns if col.startswith(prefix)]\n",
    "                main_df.drop(columns=matching_columns, inplace=True)\n",
    "                if len(df) <= len(main_df):\n",
    "                    #Update the old df by merging with new df - INNER JOIN \n",
    "                    main_df = pd.merge(main_df, df, left_index=True, right_index=True, how='inner')\n",
    "                else: \n",
    "                    data_loader_format_all(ticker, start_date, end_date)\n",
    "\n",
    "        except Exception as e:\n",
    "            return html.Div(f\"Failed to load data for {ticker}: {str(e)}\"), {'Price Plot' : None, 'start' : None, 'end' : None}  \n",
    "    \n",
    "    elif session_data:\n",
    "        if 'Price Plot' in session_data and session_data['Price Plot']:\n",
    "            json_str = session_data['Price Plot']\n",
    "            try:\n",
    "                json_dump = pd.read_json(json_str, orient='split')\n",
    "                key = 1 \n",
    "            except ValueError as e:\n",
    "                print(\"Error loading JSON data:\", e)\n",
    "                return html.Div(\"Failed to load data.\"), {'Price Plot': None, 'start': None, 'end': None}\n",
    "\n",
    "    #Select subset of main_df \n",
    "    sub_df = prepare_and_scale_df(main_df, json_dump, key, scale)\n",
    "    \n",
    "    fig = plot_fig(sub_df)\n",
    "\n",
    "    #UPDATE TO GLOBAL VARIABLES\n",
    "    list_tickers.append(ticker)\n",
    "    list_tickers = list(set(list_tickers))\n",
    "\n",
    "    dict_classes[asset_class].append(ticker)\n",
    "    dict_classes[asset_class] = list(set(dict_classes[asset_class]))\n",
    "\n",
    "#     if asset_class == 'Commodities':\n",
    "#         dict_commo[asset_sector].append(ticker)\n",
    "#         dict_commo[asset_sector] = list(set(dict_commo[asset_sector]))\n",
    "#     if asset_class == 'Equity':\n",
    "#         dict_sectors[asset_sector].append(ticker)\n",
    "#         dict_sectors[asset_sector] = list(set(dict_sectors[asset_sector]))\n",
    "\n",
    "    return dcc.Graph(figure=fig), {'Price Plot' : sub_df.to_json(date_format='iso', orient='split'), \n",
    "                                   'start' : start_time, \n",
    "                                   'end' : end_time}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('sector-dropdown', 'options'),\n",
    "#     [Input('asset-class-dropdown', 'value')]\n",
    "# )\n",
    "# def set_sectors_options(selected_asset_class):\n",
    "#     if selected_asset_class == 'Equity':\n",
    "#         return [{'label': 'Technology', 'value': 'Technology'},\n",
    "#                 {'label': 'Consumer', 'value': 'Consumer'},\n",
    "#                 {'label': 'Utilities', 'value': 'Uitilies'},\n",
    "#                 {'label': 'Industrial', 'value': 'Consumer'},\n",
    "#                 {'label': 'Financials', 'value': 'Financials'},\n",
    "#                 {'label': 'Other', 'value': 'Other'},]\n",
    "#     elif selected_asset_class == 'Commodities':\n",
    "#         return [{'label': 'Agriculture', 'value': 'Agriculture'},\n",
    "#                 {'label': 'Precious Metals', 'value': 'Precious Metals'},\n",
    "#                 {'label': 'Industrials', 'value': 'Industrials'},\n",
    "#                 {'label': 'Energy', 'value': 'Energy'}]\n",
    "#     else:\n",
    "#         return [{'label' : 'N/A', 'value' : 'N/A'}]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('span-input', 'value'),\n",
    "    [Input('date-picker', 'date'),\n",
    "     Input('span-input', 'value')]\n",
    ")\n",
    "def debugging(ref_date, span):\n",
    "    \n",
    "    #First : Check if Span input is indeed a positive int\n",
    "    assert isinstance(span, int)\n",
    "    assert span >= 0, \"span must be a positive integer\"\n",
    "    \n",
    "    #Second : Debugging the Ref_Date \n",
    "    if ref_date not in main_df.index:\n",
    "        print('Ref_date not in df.index')\n",
    "        ref_date = main_df.index[0]\n",
    "    else: \n",
    "        ref_date = ref_date \n",
    "    \n",
    "    #Third : Debugging the Span  \n",
    "    #Retrieve position of the current date\n",
    "    position = main_df.index.get_loc(ref_date) + 1\n",
    "    if 2*span > position: #because we need 2 periods of length span \n",
    "        print('Span too high compared to index position. Rescaling')\n",
    "        span = position // 2\n",
    "\n",
    "    print(f'Select position : {main_df.index[span]} minimum for a span window of {span}.')\n",
    "\n",
    "    return span\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [Output('network-graph', 'figure'),\n",
    "     Output('heatmap-relative', 'figure'),\n",
    "     Output('heatmap-directional', 'figure'),\n",
    "     Output('store-corr-threshold', 'data'),\n",
    "     Output('store-span', 'data'),\n",
    "     Output('store-selected-date', 'data'),\n",
    "     Output('error-message', 'children')],\n",
    "    [Input('date-picker', 'date'),\n",
    "     Input('corr-threshold-slider', 'value'), \n",
    "     Input('span-input', 'value')]\n",
    ")\n",
    "def update_graph(selected_date, corr_threshold, span):\n",
    "    global main_df\n",
    "    \n",
    "    #Only selecting the columns which are named as \"Ticker : Log-Returns\" from main_df\n",
    "    suffix = 'Log-Returns'\n",
    "    subset_cols = [col for col in list(main_df.columns) if col.endswith(suffix)]\n",
    "    subset_df = main_df[subset_cols]\n",
    "    subset_df.columns = list_tickers\n",
    "    \n",
    "    \n",
    "    span = debugging(selected_date, span)\n",
    "    \n",
    "    if selected_date is not None and corr_threshold is not None:\n",
    "        # Check if selected_date is valid using rolling_corr or equivalent function\n",
    "        corr_result = rolling_corr(subset_df, selected_date, span)  \n",
    "        if isinstance(corr_result, str) and corr_result == \"Date not found\":\n",
    "            return dash.no_update, dash.no_update, dash.no_update, corr_threshold, span, {'date' : selected_date}, \"Error: Selected date not found in the dataset.\"\n",
    "        else:\n",
    "            try: \n",
    "                network_fig = graph_net(subset_df, selected_date, corr_threshold=corr_threshold, span=span)\n",
    "                heatmap_relative_graph, heatmap_directional_graph = rolling_corr_difference(subset_df, selected_date, span=span)\n",
    "                return network_fig, heatmap_relative_graph, heatmap_directional_graph, corr_threshold, span, selected_date, \"\"\n",
    "            \n",
    "            except Exception as e:\n",
    "                return dash.no_update, dash.no_update, dash.no_update, corr_threshold, span, {'date' : selected_date}, f\"Error: {str(e)}\"\n",
    "    else:\n",
    "        return dash.no_update, dash.no_update, dash.no_update, corr_threshold, span, {'date' : selected_date}, \"\" \n",
    "\n",
    "    \n",
    "@app.callback(\n",
    "    [Output('date-picker', 'min_date_allowed'),\n",
    "     Output('date-picker', 'max_date_allowed'),\n",
    "     Output('date-picker', 'initial_visible_month'),\n",
    "     Output('date-picker', 'date')],\n",
    "    [Input('session-data', 'data')],\n",
    ")\n",
    "def update_date_picker(session_data):\n",
    "    if session_data:\n",
    "        min_date = session_data.get('start')\n",
    "        max_date = session_data.get('end')\n",
    "        return min_date, max_date, min_date, min_date\n",
    "\n",
    "    default_date = datetime.datetime.today().date()\n",
    "    return default_date, default_date, default_date, default_date\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "@app.callback(\n",
    "    Output('ticker-dropdown', 'options'),\n",
    "    Input('url', 'pathname'),\n",
    ")\n",
    "def update_dropdown_options(pathname):\n",
    "    global list_tickers, counter\n",
    "    \n",
    "    if pathname.endswith('/portfolio') and counter == 0:\n",
    "        print(list_tickers)\n",
    "        options = [{'label': ticker, 'value': ticker} for ticker in list_tickers]\n",
    "        print(f\"Dropdown options updated: {options}\")\n",
    "        counter += 1\n",
    "        return options\n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [\n",
    "        Output('remaining-weight', 'children'),\n",
    "        Output('weight-slider', 'max'),\n",
    "        Output('weight-slider', 'value'),\n",
    "        Output('weights-table', 'data'),\n",
    "        Output('weights-table', 'columns')\n",
    "    ],\n",
    "    [   Input('confirm-weight-btn', 'n_clicks'),\n",
    "        Input('reset-button', 'n_clicks')],\n",
    "    [\n",
    "        State('weight-slider', 'value'),\n",
    "        State('ticker-dropdown', 'value'),\n",
    "        State('weights-table', 'data'),\n",
    "        State('weight-slider', 'max')]\n",
    ")\n",
    "def confirm_weight(n_clicks, reset, slider_value, ticker, data, current_max):\n",
    "#     print(list_tickers)\n",
    "    print(f\"Confirm weight called with: {n_clicks}, {slider_value}, {ticker}, {current_max}\")\n",
    "    if n_clicks is None:\n",
    "        raise PreventUpdate\n",
    "\n",
    "    # Avoid duplicate entries if button is clicked more than once quickly\n",
    "    if data and data[-1]['ticker'] == ticker and data[-1]['weight'] == slider_value:\n",
    "        return dash.no_update\n",
    "\n",
    "    data.append({'ticker': ticker, 'weight': slider_value})\n",
    "    new_max = current_max - slider_value\n",
    "    \n",
    "    if reset: \n",
    "        new_max = 100 \n",
    "        return f'Remaining Weight: {new_max}', new_max, 0, data, []\n",
    "    \n",
    "    return f'Remaining Weight: {new_max}', new_max, 0, data, [{'name': 'Ticker', 'id': 'ticker'}, {'name': 'Weight', 'id': 'weight'}]\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('portfolio-performance-graph', 'figure'),\n",
    "    Output('stock-performance-viz', 'figure'),\n",
    "    Input('launch-analysis-btn', 'n_clicks'),\n",
    "    Input('reset-button', 'n_clicks'),\n",
    "    State('weights-table', 'data')\n",
    ")\n",
    "def update_graphs(n_clicks, reset, data):\n",
    "    print(f\"Update graphs called with: {n_clicks}, data: {data}\")\n",
    "    if n_clicks is None or not data:\n",
    "        raise PreventUpdate\n",
    "\n",
    "    if reset == 0: \n",
    "        line_chart = go.Figure()\n",
    "        line_chart.add_trace(go.Scatter(x=[1, 2, 3], y=[2, 3, 4], mode='lines', name='Portfolio Value'))\n",
    "        line_chart.update_layout(title='Portfolio Performance Over Time')\n",
    "\n",
    "        bar_chart = go.Figure()\n",
    "        bar_chart.add_trace(go.Bar(x=[item['ticker'] for item in data], y=[item['weight'] for item in data], name='Stock Weight'))\n",
    "        bar_chart.update_layout(title='Stock Performance Visualization')\n",
    "\n",
    "        return line_chart, bar_chart\n",
    "    \n",
    "    else: \n",
    "        reset_graph1 = {'data': []}\n",
    "        reset_graph2 = {'data': []}\n",
    "        \n",
    "        return line_chart, bar_chart\n",
    "\n",
    "\n",
    "@callback(\n",
    "        Output('portfolio-date-picker', 'date'),\n",
    "        Input('reset-button', 'n_clicks'),\n",
    "        Input('store-selected-date', 'data')\n",
    ")\n",
    "def reset_all(n_clicks, session_data):\n",
    "    if n_clicks is None:\n",
    "        return no_update\n",
    "\n",
    "    reset_date = session_data.get('date')\n",
    "\n",
    "    return reset_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8188/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f926a3a24c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "# Run the app\n",
    "port = 8188\n",
    "\n",
    "# Open a web browser tab using the specified port\n",
    "def open_browser():\n",
    "      webbrowser.open_new_tab(f'http://127.0.0.1:{port}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Use the threading module to open a web browser tab\n",
    "    # This prevents blocking the execution of the app\n",
    "    from threading import Timer\n",
    "    Timer(1, open_browser).start()  # Wait 1 second before opening the tab\n",
    "    \n",
    "    app.run_server(debug=True, port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL']"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['META', 'AAPL']\n",
      "Dropdown options updated: [{'label': 'META', 'value': 'META'}, {'label': 'AAPL', 'value': 'AAPL'}]\n"
     ]
    }
   ],
   "source": [
    "list_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/main.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[348], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let's read the content of the file to understand the issue.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/main.py\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m     code_content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Output the first 500 characters to get a sense of the content.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/main.py'"
     ]
    }
   ],
   "source": [
    "# Let's read the content of the file to understand the issue.\n",
    "file_path = '/main.py'\n",
    "with open(file_path, 'r') as file:\n",
    "    code_content = file.read()\n",
    "\n",
    "# Output the first 500 characters to get a sense of the content.\n",
    "print(code_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
