{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e11be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import requirements\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import time\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import yahoo_fin.stock_info as si\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7870185",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_file = pd.read_csv('merged_df.csv')\n",
    "#Some text manipulation \n",
    "pattern = r\"^(.*?): Close$\"\n",
    "\n",
    "# List to hold extracted ticker names\n",
    "ticker_names = []\n",
    "column_names = main_file.columns\n",
    "\n",
    "#Matching the elements of column_names with pattern\n",
    "for col in column_names:\n",
    "    match = re.match(pattern, col)\n",
    "    if match:\n",
    "        ticker_names.append(match.group(1))  # group(1) refers to the first captured group\n",
    "\n",
    "#Creating a list with target columns from main_file : \"ticker_name: Close\"\n",
    "target_col_names = []\n",
    "for ticker in ticker_names: \n",
    "    col_name = str(ticker + ': Close')\n",
    "    target_col_names.append(col_name)\n",
    "\n",
    "main_df = main_file[target_col_names].round(2)\n",
    "\n",
    "#Creating new column names\n",
    "# new_column_names = ['AAPL', 'MC.PA', 'JPM', 'NVDA', '^SPX', 'IAU', 'CL=F', 'LQD', 'XRP-USD',\n",
    "#        'NVDA', 'LLY', 'TSLA', '^SPX','^DJI', '^RUT', 'IAU', 'CPER', 'GSG', 'CL=F', 'TLT', \n",
    "#                     'JNK', 'LQD', 'BTC-USD', 'ETH-USD', 'XRP-USD']\n",
    "\n",
    "#Renaming columns\n",
    "new_column_names = ['AAPL', 'META', 'V', 'MC.PA', 'NFLX', 'NKE', 'JPM', 'BAC', 'C',\n",
    "                    'NVDA', 'LLY', 'TSLA', '^SPX', '^DJI', '^RUT', 'IAU', 'CPER',\n",
    "                    'GSG', 'CL=F', 'TLT', 'JNK', 'LQD', 'BTC-USD', 'ETH-USD', 'XRP-USD']\n",
    "\n",
    "#Setting main_file['Date'] as index of main_df    \n",
    "main_df['Date'] = main_file['Date']\n",
    "main_df.set_index(main_df['Date'], inplace = True)\n",
    "pd.to_datetime(main_df.index, format='%Y-%m-%d')\n",
    "main_df.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# main_df.head()    #now we have in our main df columns of closing prices for each of our tickers. \n",
    "main_df.columns = new_column_names\n",
    "# main_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2078ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_corr(df, ref_date, span):\n",
    "\n",
    "    assert isinstance(span, int) and span > 0, \"span must be a positive integer\"\n",
    "    \n",
    "    # Check if ref_date is in the index\n",
    "    if ref_date not in df.index:\n",
    "        return \"Date not found\"\n",
    "    else: \n",
    "        starting_point = None\n",
    "\n",
    "        try:\n",
    "            # Convert the starting point to a Timestamp (if it's a string)\n",
    "            if isinstance(ref_date, str):\n",
    "                try: \n",
    "                    starting_point = pd.to_datetime(ref_date)\n",
    "                except ValueError as err: \n",
    "                    print(f'DateParseError : {err}')\n",
    "                    print('Please enter an input of the format : YYYY-MM-DD')\n",
    "\n",
    "            if starting_point is not None:\n",
    "\n",
    "                date = pd.to_datetime(starting_point)     \n",
    "\n",
    "                # Format the Timestamp object to a string in the desired format\n",
    "                formatted_date = starting_point.strftime('%Y-%m-%d')\n",
    "\n",
    "                # Find position of starting_point in df's index\n",
    "                position = df.index.get_loc(formatted_date)\n",
    "\n",
    "                # Calculate start position for slicing (ensure it's not negative)\n",
    "                start_position = max(position - span, 0)\n",
    "                if position - span < 0: \n",
    "                    print('Correlation period less than span. Check datetime range.')\n",
    "\n",
    "                # Filter the DataFrame to get the previous ten elements from the starting point\n",
    "                filtered_df = df.iloc[start_position:position]\n",
    "\n",
    "                corr_matrix = filtered_df.corr()\n",
    "\n",
    "                return corr_matrix.round(2)\n",
    "\n",
    "        except KeyError as err: \n",
    "            print(f'Error due to wrong date input: {err}.')\n",
    "            print(f'Recall date range of input dataframe: {df.index[0], df.index[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c5c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_change(corr1, corr2):\n",
    "    range_corr = 2\n",
    "    rel_range_change = ((corr2 - corr1) / range_corr) * 100\n",
    "    \n",
    "    return rel_range_change\n",
    "\n",
    "\n",
    "\n",
    "def matrix_difference(matrix1, matrix2):\n",
    "    # Check if the matrices have the same shape\n",
    "    if matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "    \n",
    "    # Initialize an empty matrix to store the differences\n",
    "    rows = matrix1.shape[0]\n",
    "    columns = matrix1.shape[1]\n",
    "    result_matrix = pd.DataFrame(np.zeros((rows, columns)))\n",
    "    result_matrix.columns = new_column_names\n",
    "    \n",
    "    # Iterate through the rows and columns of the matrices\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            perct_change = relative_change(matrix1.iloc[i, j], matrix2.iloc[i, j])\n",
    "            result_matrix.iloc[i, j] = perct_change\n",
    "    return result_matrix\n",
    "\n",
    "\n",
    "\n",
    "def matrix_difference_qual(matrix1, matrix2, heatmap=True):\n",
    "    category_map = None\n",
    "    # Check if the matrices have the same shape\n",
    "    if matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "    \n",
    "    # Initialize an empty matrix to store the differences\n",
    "    rows = matrix1.shape[0]\n",
    "    columns = matrix1.shape[1]\n",
    "    result_matrix = pd.DataFrame(np.zeros((rows, columns)))\n",
    "    result_matrix.columns = new_column_names\n",
    "    \n",
    "    # Iterate through the rows and columns of the matrices\n",
    "    for i in range(matrix1.shape[0]):\n",
    "        for j in range(matrix1.shape[1]):\n",
    "            # Perform differentiation based on the values of the elements\n",
    "            if matrix1.iloc[i, j] < 0 and matrix2.iloc[i, j] < 0:\n",
    "                if matrix2.iloc[i, j] > matrix1.iloc[i, j]:\n",
    "                    result_matrix.iloc[i, j] = 'Neg Stronger'\n",
    "                else:\n",
    "                    result_matrix.iloc[i, j] = 'Neg Weaker'\n",
    "            elif matrix1.iloc[i, j] > 0 and matrix2.iloc[i, j] > 0:\n",
    "                if matrix2.iloc[i, j] > matrix1.iloc[i, j]:\n",
    "                    result_matrix.iloc[i, j] = 'Pos Stronger'\n",
    "                else:\n",
    "                    result_matrix.iloc[i, j] = 'Pos Weaker'\n",
    "            elif matrix1.iloc[i, j] > 0 and matrix2.iloc[i, j] < 0:\n",
    "                result_matrix.iloc[i, j] = 'Neg Stronger'\n",
    "            elif matrix1.iloc[i, j] < 0 and matrix2.iloc[i, j] > 0:\n",
    "                result_matrix.iloc[i, j] = 'Pos Stronger'\n",
    "            elif 0.95 <= matrix1.iloc[i, j] / matrix2.iloc[i, j] <= 1.05:\n",
    "                result_matrix.iloc[i, j] = 'UNCH'\n",
    "    if heatmap: \n",
    "        category_map = {'Neg Stronger': -10, 'Neg Weaker': -5, \n",
    "                        'Pos Stronger': 10, 'Pos Weaker': 5, \n",
    "                        'UNCH': 0}\n",
    "        df_numeric = result_matrix.applymap(lambda x: category_map[x])\n",
    "        \n",
    "        return df_numeric\n",
    "\n",
    "    else: \n",
    "        print(\"Can't return a heatmap - Categ Variables of String Type\")\n",
    "        return result_matrix\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def rolling_corr_difference(df, ref_date, span):\n",
    "    \n",
    "    assert isinstance(span, int) and span > 0, \"span must be a positive integer\"\n",
    "\n",
    "    # Calculate correlation matrix for the current span\n",
    "    corr_matrix_current = rolling_corr(df, ref_date, span=span)\n",
    "    \n",
    "    # Calculate the previous corr matrix's ref_date\n",
    "    index_position = df.index.get_loc(ref_date)\n",
    "    # Previous corr matrix's ref index position is max(0, index_position - span)\n",
    "    temp_index_position = index_position - span \n",
    "    if temp_index_position < 0: \n",
    "        print(f'Period out of bound. Setting reference date to {df.index[0]}')\n",
    "        temp_index_position = 0\n",
    "\n",
    "    new_index_position = df.index.get_loc(df.index[temp_index_position])\n",
    "    new_ref_date = df.index[new_index_position]\n",
    "\n",
    "    # Calculate correlation matrix for the previous span\n",
    "    corr_matrix_prev = rolling_corr(df, new_ref_date, span=span)\n",
    "    \n",
    "    # Calculate the difference between correlation matrices\n",
    "    corr_diff = matrix_difference(corr_matrix_prev, corr_matrix_current)\n",
    "    corr_diff_qual = matrix_difference_qual(corr_matrix_prev, corr_matrix_current)\n",
    "\n",
    "\n",
    "    # Plotting heatmap\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    colors = [(1, 0, 0), (1, 1, 0.75), (0, 0.5, 0)]  # Red to green\n",
    "    cmap = sns.blend_palette(colors, as_cmap=True)\n",
    "    sns.heatmap(corr_diff, annot=True, cmap=cmap, fmt=\".1f\", xticklabels=new_column_names, yticklabels=new_column_names)\n",
    "    plt.title(f'Relative Range Percentage Change of Rolling Correlations between Assets Log Returns, {span} freq periods.')\n",
    "    plt.xlabel('Assets')\n",
    "    plt.ylabel('Assets')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting heatmap\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(corr_diff, annot=False, cmap='coolwarm', fmt=\".2f\", xticklabels=new_column_names, yticklabels=new_column_names)\n",
    "    plt.title(f'Directional Difference between Rolling Correlation Matrices of Assets Log Returns, {span} freq periods.')\n",
    "    plt.xlabel('Assets')\n",
    "    plt.ylabel('Assets')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return corr_diff, corr_diff_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f1c746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KAMADA KAWAI LAYOUT\n",
    "\n",
    "\n",
    "def graph_net(df, ref_date, corr_threshold, span):\n",
    "    corr_matrix = rolling_corr(main_df, ref_date, span)\n",
    "    # Create a graph from the correlation matrix\n",
    "    G = nx.Graph()\n",
    "\n",
    "    #Ticker Categs & Coloring:\n",
    "    ticker_categs = {\n",
    "        'Equity': ['AAPL', 'META', 'V', 'MC.PA', 'NFLX', 'NKE', 'JPM', 'BAC', 'C', 'NVDA', 'LLY', 'TSLA'],\n",
    "        'Index': ['^SPX', '^DJI', '^RUT'],\n",
    "        'Credit': ['TLT', 'JNK', 'LQD'],\n",
    "        'Commodities': ['IAU', 'CPER', 'GSG', 'CL=F'],\n",
    "        'Crypto': ['BTC-USD', 'ETH-USD', 'XRP-USD']               \n",
    "    }\n",
    "\n",
    "    colors = {\n",
    "        'Equity' : 'yellow',\n",
    "        'Index' : 'blue',\n",
    "        'Credit' : 'red',\n",
    "        'Commodities': 'orange',\n",
    "        'Crypto': 'green'\n",
    "    }\n",
    "\n",
    "\n",
    "    # Add edges to the graph\n",
    "    for col1 in corr_matrix.columns:\n",
    "        for col2 in corr_matrix.index:\n",
    "            corr = corr_matrix.loc[col1, col2]\n",
    "            # Add edge if absolute correlation is above the threshold and avoid duplicate edges\n",
    "            if abs(corr) > x and col1 != col2:\n",
    "                # Check if the edge already exists (undirected graph, so A->B is the same as B->A)\n",
    "                if not G.has_edge(col1, col2) and not G.has_edge(col2, col1):\n",
    "                    G.add_edge(col1, col2, weight=corr)\n",
    "\n",
    "    # Assuming 'G' is your original graph with 'weight' attributes holding the correlations\n",
    "    H = G.copy()\n",
    "\n",
    "    # Update edge weights in H to be absolute values of the original weights\n",
    "    for u, v, d in H.edges(data=True):\n",
    "        d['weight'] = abs(d['weight'])\n",
    "\n",
    "\n",
    "    # Assuming H is your graph for layout and G contains original correlation weights\n",
    "    pos = nx.kamada_kawai_layout(H)\n",
    "    # pos = nx.shell_layout(H)\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=700, node_color='skyblue', alpha=0.6)\n",
    "\n",
    "    # Separate positive and negative correlations\n",
    "    positive_edges = [(u, v, d) for u, v, d in G.edges(data=True) if d['weight'] > 0]\n",
    "    negative_edges = [(u, v, d) for u, v, d in G.edges(data=True) if d['weight'] < 0]\n",
    "\n",
    "    # Define normalization based on the range of correlation values\n",
    "    # This normalization will be used to map correlation values to colors\n",
    "    max_positive_corr = max(abs(d['weight']) for u, v, d in positive_edges) if positive_edges else 0\n",
    "    max_negative_corr = max(abs(d['weight']) for u, v, d in negative_edges) if negative_edges else 0\n",
    "\n",
    "    # Function to get color intensity based on correlation\n",
    "    def get_color_intensity(corr_value, max_corr):\n",
    "        return corr_value**3 / max_corr**3 if max_corr else 0.0  # Avoid division by zero\n",
    "\n",
    "\n",
    "    # Draw nodes with colors based on categories, if the node is found in the ticker_categs dictionary\n",
    "    for category, nodes in ticker_categs.items():\n",
    "        valid_nodes = [node for node in nodes if node in G.nodes()]\n",
    "        nx.draw_networkx_nodes(G, pos,\n",
    "                               nodelist=valid_nodes,\n",
    "                               node_size=700,\n",
    "                               node_color=colors[category],\n",
    "                               alpha=0.6)\n",
    "\n",
    "    # Draw positive edges with varying shades of green\n",
    "    for u, v, d in positive_edges:\n",
    "        intensity = get_color_intensity(abs(d['weight']), max_positive_corr)\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=[(u, v)], width=2,\n",
    "                               edge_color=[(0, intensity, 0, 1)])  # RGBA tuple\n",
    "\n",
    "    # Draw negative edges with varying shades of red\n",
    "    for u, v, d in negative_edges:\n",
    "        intensity = get_color_intensity(abs(d['weight']), max_negative_corr)\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=[(u, v)], width=2,\n",
    "                               edge_color=[(intensity, 0, 0, 1)])  # RGBA tuple\n",
    "\n",
    "\n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "\n",
    "    # Create legend patches\n",
    "    import matplotlib.patches as mpatches\n",
    "    legend_patches = [mpatches.Patch(color=color, label=category) for category, color in colors.items()]\n",
    "    plt.legend(handles=legend_patches)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight')\n",
    "    buf.seek(0)\n",
    "    plt.close()  \n",
    "\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b07d3411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Vars\n",
    "x = 0.9\n",
    "ref_date = '2024-02-14'\n",
    "span = 5\n",
    "new_column_names = ['AAPL', 'META', 'V', 'MC.PA', 'NFLX', 'NKE', 'JPM', 'BAC', 'C',\n",
    "                    'NVDA', 'LLY', 'TSLA', '^SPX', '^DJI', '^RUT', 'IAU', 'CPER',\n",
    "                    'GSG', 'CL=F', 'TLT', 'JNK', 'LQD', 'BTC-USD', 'ETH-USD', 'XRP-USD']\n",
    "\n",
    "#for dash app\n",
    "dates_list = main_df.index.tolist()\n",
    "dash_df = main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00d7cacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
      "On macOS, try disabling the 'AirPlay Receiver' service from System Preferences -> Sharing.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/werkzeug/serving.py:911\u001b[0m, in \u001b[0;36mprepare_socket\u001b[0;34m(hostname, port)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 48] Address already in use",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[24], line 23\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flask/app.py:1188\u001b[0m, in \u001b[0;36mFlask.run\u001b[0;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[43mrun_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;66;03m# reset the first request information if the development server\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;66;03m# reset normally.  This makes it possible to restart the server\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;66;03m# without reloader and that stuff from an interactive shell.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/werkzeug/serving.py:1062\u001b[0m, in \u001b[0;36mrun_simple\u001b[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, exclude_patterns, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_running_from_reloader():\n\u001b[0;32m-> 1062\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhostname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m     fd \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mfileno()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/werkzeug/serving.py:930\u001b[0m, in \u001b[0;36mprepare_socket\u001b[0;34m(hostname, port)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    925\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOn macOS, try disabling the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAirPlay Receiver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    926\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m service from System Preferences -> Sharing.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    927\u001b[0m                 file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    928\u001b[0m             )\n\u001b[0;32m--> 930\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m s\u001b[38;5;241m.\u001b[39mlisten(LISTEN_QUEUE)\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:2047\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2045\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2046\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2047\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2048\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2051\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   2053\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:585\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    578\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \n\u001b[1;32m    580\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:452\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    449\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    450\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    451\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 452\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:1118\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m tb\n\u001b[0;32m-> 1118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:1012\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1009\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:865\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    858\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    862\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    863\u001b[0m ):\n\u001b[1;32m    864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:799\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    797\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(etype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m    798\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    800\u001b[0m )\n\u001b[1;32m    802\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    803\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:854\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    848\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    849\u001b[0m options \u001b[38;5;241m=\u001b[39m stack_data\u001b[38;5;241m.\u001b[39mOptions(\n\u001b[1;32m    850\u001b[0m     before\u001b[38;5;241m=\u001b[39mbefore,\n\u001b[1;32m    851\u001b[0m     after\u001b[38;5;241m=\u001b[39mafter,\n\u001b[1;32m    852\u001b[0m     pygments_formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[1;32m    853\u001b[0m )\n\u001b[0;32m--> 854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[tb_offset:]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stack_data/core.py:578\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[0;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_data\u001b[39m(\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m         collapse_repeated_frames: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    569\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrameInfo\u001b[39m\u001b[38;5;124m'\u001b[39m, RepeatedFrames]]:\n\u001b[1;32m    570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;66;03m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;66;03m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;66;03m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py:97\u001b[0m, in \u001b[0;36miter_stack\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m frame_or_tb:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m frame_or_tb\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     98\u001b[0m         frame_or_tb \u001b[38;5;241m=\u001b[39m frame_or_tb\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py:90\u001b[0m, in \u001b[0;36mis_frame\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[43massert_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTracebackType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame_or_tb, (types\u001b[38;5;241m.\u001b[39mFrameType,))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stack_data/utils.py:176\u001b[0m, in \u001b[0;36massert_\u001b[0;34m(condition, error)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    175\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAssertionError\u001b[39;00m(error)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, send_file\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    available_dates = dates_list[11:]\n",
    "    return render_template('index.html', available_dates=available_dates)\n",
    "\n",
    "@app.route('/plot', methods=['POST'])\n",
    "def plot():\n",
    "    selected_date = request.form.get('selected_date')\n",
    "    corr_threshold = 0.5  # Adjust as needed\n",
    "    span = 5  # Fixed span\n",
    "    \n",
    "    plot_buf = graph_net(dash_df, ref_date, corr_threshold, span)\n",
    "    \n",
    "    return send_file(plot_buf, mimetype='image/png')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83a342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
