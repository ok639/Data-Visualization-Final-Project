{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS : \n",
    "\n",
    "\n",
    "import time\n",
    "import re \n",
    "\n",
    "from functools import reduce\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import yfinance as yf \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import dash \n",
    "from dash import Dash \n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.exceptions import PreventUpdate\n",
    "from dash import dcc, html, callback, callback_context, Input, Output, State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you want to keep a main dataframe to store or update data\n",
    "main_df = pd.DataFrame()\n",
    "available_dates = main_df.index.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to record : Asset Classes & tickers within \n",
    "\n",
    "initializer = True \n",
    "\n",
    "dict_classes = {\n",
    "    'Equity' : [],\n",
    "    'Commodities' : [],\n",
    "    'Fixed Income' : [],\n",
    "    'Forex' : [],\n",
    "}\n",
    "\n",
    "dict_sectors = {\n",
    "    'Financials' : [],\n",
    "    'Technology' : [],\n",
    "    'Industrial' : [],\n",
    "    'Consumer' : [],\n",
    "    'Utilities' : [],\n",
    "    'Other' : []\n",
    "}\n",
    "\n",
    "dict_commo = {\n",
    "    'Agriculture' : [],\n",
    "    'Precious Metals' : [],\n",
    "    'Energy' : [],\n",
    "    'Industrials' : []\n",
    "}\n",
    "\n",
    "list_tickers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAGE 1 : HOME \n",
    "\n",
    "def reset_global_vars():\n",
    "    global initializer, dict_classes, dict_sectors, dict_commo, list_tickers\n",
    "    \n",
    "    initializer = True \n",
    "    \n",
    "    dict_classes = {\n",
    "    'Equity' : [],\n",
    "    'Commodities' : [],\n",
    "    'Fixed Income' : [],\n",
    "    'Forex' : [],\n",
    "    }\n",
    "\n",
    "    dict_sectors = {\n",
    "        'Financials' : [],\n",
    "        'Technology' : [],\n",
    "        'Industrial' : [],\n",
    "        'Consumer' : [],\n",
    "        'Utilities' : [],\n",
    "        'Other' : []\n",
    "    }\n",
    "\n",
    "    dict_commo = {\n",
    "        'Agriculture' : [],\n",
    "        'Precious Metals' : [],\n",
    "        'Energy' : [],\n",
    "        'Industrials' : []\n",
    "    }\n",
    "\n",
    "    list_tickers = []\n",
    "    \n",
    "def scaled_df(df):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=df.columns, index=df.index)\n",
    "\n",
    "    return scaled_df\n",
    "\n",
    "\n",
    "def get_logreturn(df_price_col):\n",
    "    return np.log(df_price_col / df_price_col.shift(1)) * 100 \n",
    "\n",
    "\n",
    "def minmax_scaler(df, spread = 1):\n",
    "    min_df = df.min()\n",
    "    max_df = df.max() \n",
    "    \n",
    "    df = df.apply(lambda x : ((x-min_df) / (max_df - min_df)) / spread)\n",
    "    \n",
    "    return df \n",
    "\n",
    "\n",
    "def data_loader(ticker_name, start, end, interval='1d'):\n",
    "    ticker = ticker_name \n",
    "    try : \n",
    "        df = yf.download(ticker, start=start, end=end)\n",
    "        \n",
    "    \n",
    "        if len(df) != 0: \n",
    "            date_column = df.index\n",
    "            df = df.sort_index()\n",
    "\n",
    "            #Daily price normalized to the total volume of the dataset\n",
    "            df['price_volume'] = df['Adj Close'] * df['Volume']\n",
    "            df['Norm_PV'] = (df['price_volume'] / df['Volume'].sum()) #Norm_PV = Normalized Price Volume\n",
    "\n",
    "            #Renaming (for merging purposes):\n",
    "            title_1 = ticker + ': Adj Close'\n",
    "            title_2 = ticker + ': Norm_PV'\n",
    "            title_3 = ticker + ': Log-Returns'\n",
    "\n",
    "            #Log-returns\n",
    "            df[title_3] = get_logreturn(df['Adj Close']) #Results are in %\n",
    "            df.drop(columns = ['Open', 'High', 'Low', 'Adj Close', 'Volume', 'price_volume'], axis = 1, inplace = True)\n",
    "\n",
    "            df.rename(columns={'Close': title_1,\n",
    "                                    'Norm_PV': title_2,\n",
    "                                   }, inplace=True)\n",
    "            pd.to_datetime(df.index, format='%Y-%m-%d')\n",
    "\n",
    "        return df \n",
    "    \n",
    "    except Exception as e: \n",
    "        return e\n",
    "\n",
    "\n",
    "\n",
    "def data_loader_format_all(ticker, start, end, interval='1d'):\n",
    "    global main_df, list_tickers\n",
    "    \n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    temp = list_tickers \n",
    "    temp.append(ticker)\n",
    "    temp = set(temp)\n",
    "    \n",
    "    for i, tick in enumerate(temp):             \n",
    "        if i == 0: \n",
    "            main_df = data_loader(tick, start, end)\n",
    "            continue\n",
    "        df = data_loader(tick, start, end)\n",
    "        main_df = pd.merge(main_df, df, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "    return \"All ticker frames updated.\" \n",
    "\n",
    "\n",
    "def curve_plotter(df, mode='price', scaled=False):\n",
    "    global list_tickers \n",
    "    if mode == 'return':\n",
    "        scaled=False\n",
    "        suffix='Returns'\n",
    "    else: \n",
    "        suffix='Adj Close'\n",
    "        \n",
    "    matching_columns = [col for col in df.columns if col.endswith(suffix)]\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "    df.drop(matching_columns, axis=1, inplace=True)   \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def prepare_and_scale_df(df1, df2, key, scale):\n",
    "    if key == 0:\n",
    "        col_list = list(df1.columns)\n",
    "        adj_close_list = [item for item in col_list if \"Adj Close\" in item]\n",
    "        sub_df = df1[adj_close_list]\n",
    "        sub_df.columns = [re.sub(r'^\\s+|\\s+$', '', col.split(\":\")[0]) for col in adj_close_list]\n",
    "    else:\n",
    "        col_list = list(df2.columns)\n",
    "        adj_close_list = [item for item in col_list if \"Adj Close\" in item]\n",
    "        sub_df = df2[adj_close_list]\n",
    "        sub_df.columns = [re.sub(r'^\\s+|\\s+$', '', col.split(\":\")[0]) for col in adj_close_list]\n",
    "\n",
    "    if scale and not sub_df.empty:\n",
    "        sub_df = scaled_df(sub_df)\n",
    "    \n",
    "    return sub_df\n",
    "\n",
    "\n",
    "def plot_fig(df):\n",
    "    fig = go.Figure()\n",
    "    for ticker in df.columns:\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=df[ticker], mode='lines', name=ticker))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Adjusted Close Prices Over Time for selected tickers',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Adjusted Close Price',\n",
    "        legend_title=\"Ticker\"\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAGE 2 : ANALYTICS \n",
    "\n",
    "\n",
    "def relative_change(corr1, corr2):\n",
    "    range_corr = 2\n",
    "    rel_range_change = ((corr2 - corr1) / range_corr) * 100\n",
    "    \n",
    "    return rel_range_change        \n",
    "\n",
    "\n",
    "\n",
    "def rolling_corr(df, ref_date, span):\n",
    "    try:\n",
    "        position = df.index.get_loc(ref_date) + 1\n",
    "        start_position = position - span\n",
    "        filtered_df = df.iloc[start_position:position]\n",
    "        corr_matrix = filtered_df.corr()\n",
    "\n",
    "        return corr_matrix.round(2)\n",
    "\n",
    "    except KeyError as err: \n",
    "        print(f'Error due to wrong date/span input: {err}, Date : {ref_date}, Span : {span}.')\n",
    "        print(f'Recall date range of input dataframe: {df.index[0], df.index[-1]}')\n",
    "\n",
    "    \n",
    "\n",
    "def matrix_difference(matrix1, matrix2):\n",
    "    # Check if the matrices have the same shape\n",
    "    if matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "    \n",
    "    # Initialize an empty matrix to store the differences\n",
    "    rows = matrix1.shape[0]\n",
    "    columns = matrix1.shape[1]\n",
    "    result_matrix = pd.DataFrame(np.zeros((rows, columns)))\n",
    "    result_matrix.columns = list_tickers\n",
    "    \n",
    "    # Iterate through the rows and columns of the matrices\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            perct_change = relative_change(matrix1.iloc[i, j], matrix2.iloc[i, j])\n",
    "            result_matrix.iloc[i, j] = perct_change       \n",
    "    return result_matrix\n",
    "\n",
    "\n",
    "\n",
    "def matrix_difference_qual(matrix1, matrix2, heatmap=True):\n",
    "    category_map = None\n",
    "\n",
    "    # Check if the matrices have the same shape\n",
    "    if matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "    \n",
    "    # Initialize an empty matrix to store the differences\n",
    "    rows = matrix1.shape[0]\n",
    "    columns = matrix1.shape[1]\n",
    "    result_matrix = pd.DataFrame(np.zeros((rows, columns)))\n",
    "    result_matrix.columns = list_tickers\n",
    "    \n",
    "    # Iterate through the rows and columns of the matrices\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            # Perform differentiation based on the values of the elements\n",
    "            \n",
    "            if matrix1.iloc[i, j] == 0 or matrix2.iloc[i, j] == 0:\n",
    "                if matrix1.iloc[i, j] < 0:\n",
    "                    matrix2.iloc[i,j] = -0.00001\n",
    "                elif matrix1.iloc[i,j] > 0: \n",
    "                    matrix2.iloc[i,j] = 0.00001\n",
    "                elif matrix2.iloc[i,j] < 0: \n",
    "                    matrix1.iloc[i,j] = 0.00001\n",
    "                elif matrix2.iloc[i,j] > 0: \n",
    "                    matrix1.iloc[i,j] = -0.00001\n",
    "                    \n",
    "            if matrix1.iloc[i, j] < 0 and matrix2.iloc[i, j] < 0:\n",
    "                if matrix2.iloc[i, j] > matrix1.iloc[i, j]:\n",
    "                    result_matrix.iloc[i, j] = 'Neg Stronger'\n",
    "                else:\n",
    "                    result_matrix.iloc[i, j] = 'Neg Weaker'\n",
    "            elif matrix1.iloc[i, j] > 0 and matrix2.iloc[i, j] > 0:\n",
    "                if matrix2.iloc[i, j] > matrix1.iloc[i, j]:\n",
    "                    result_matrix.iloc[i, j] = 'Pos Stronger'\n",
    "                else:\n",
    "                    result_matrix.iloc[i, j] = 'Pos Weaker'\n",
    "            elif matrix1.iloc[i, j] > 0 and matrix2.iloc[i, j] < 0:\n",
    "                result_matrix.iloc[i, j] = 'Neg Stronger'\n",
    "            elif matrix1.iloc[i, j] < 0 and matrix2.iloc[i, j] > 0:\n",
    "                result_matrix.iloc[i, j] = 'Pos Stronger'\n",
    "            elif 0.95 <= matrix1.iloc[i, j] / matrix2.iloc[i, j] <= 1.05:\n",
    "                result_matrix.iloc[i, j] = 'UNCH'\n",
    "            else: \n",
    "                print(matrix1.iloc[i, j], matrix2.iloc[i,j])\n",
    "                print(list_tickers[i], list_tickers[j])\n",
    "                \n",
    "    if heatmap: \n",
    "        category_map = {'Neg Stronger': -10, 'Neg Weaker': -5, \n",
    "                        'Pos Stronger': 10, 'Pos Weaker': 5, \n",
    "                        'UNCH': 0}\n",
    "        df_numeric = result_matrix.applymap(lambda x: category_map[x])\n",
    "        df_numeric.index = list_tickers\n",
    "        \n",
    "        return df_numeric\n",
    "\n",
    "    else: \n",
    "        print(\"Can't return a heatmap - Categ Variables of String Type\")\n",
    "        return result_matrix\n",
    "\n",
    "    \n",
    "\n",
    "def rolling_corr_difference(df, ref_date, span):\n",
    "    \n",
    "    # Calculate correlation matrix for the current span\n",
    "    corr_matrix_current = rolling_corr(df, ref_date, span)\n",
    "    \n",
    "    # Get the previous corr matrix's ref_date\n",
    "    index_position = df.index.get_loc(ref_date)\n",
    "    \n",
    "    # Previous corr matrix's ref index position is max(0, index_position - span)\n",
    "    temp_index_position = index_position - span \n",
    "    if temp_index_position < 0: \n",
    "        print(f'Period for Previous Corr Matrix calculation out of bound. Setting reference date to {df.index[0]}')\n",
    "        span = index_position\n",
    "\n",
    "    new_index_position = df.index.get_loc(df.index[temp_index_position])\n",
    "    new_ref_date = df.index[new_index_position]\n",
    "\n",
    "    # Calculate correlation matrix for the previous span\n",
    "    corr_matrix_prev = rolling_corr(df, new_ref_date, span)\n",
    "    \n",
    "    # Calculate the difference between correlation matrices\n",
    "    corr_diff = matrix_difference(corr_matrix_prev, corr_matrix_current)\n",
    "    corr_diff_qual = matrix_difference_qual(corr_matrix_prev, corr_matrix_current)\n",
    "    \n",
    "    column_names = df.columns.tolist()\n",
    "    \n",
    "    #MASKING FOR HALF HEAT MAPs\n",
    "    mask = np.triu(np.ones_like(corr_diff, dtype=bool))\n",
    "    corr_diff_masked = np.where(mask, None, corr_diff)  # Replace upper triangular part with None\n",
    "    \n",
    "    mask_qual = np.triu(np.ones_like(corr_diff_qual, dtype=bool))\n",
    "    corr_diff_qual_masked = np.where(mask_qual, None, corr_diff_qual)  # Replace upper triangular part with None\n",
    "\n",
    "    \n",
    "    # Plotting heatmap for relative range percentage change\n",
    "    fig_relative = go.Figure(data=go.Heatmap(z=corr_diff_masked, colorscale='RdYlGn',\n",
    "                                             x=column_names, y=column_names))\n",
    "    fig_relative.update_layout(title=f'Relative Range Percentage Change of Rolling Correlations between Assets Log Returns, {span} freq periods.',\n",
    "                               xaxis_title='Assets', yaxis_title='Assets',                           \n",
    "                               plot_bgcolor='white',  paper_bgcolor='white')\n",
    "\n",
    "    # Assuming `corr_diff_qual` is plotted here instead\n",
    "    fig_directional = go.Figure(data=go.Heatmap(z=corr_diff_qual_masked, colorscale='bluered',\n",
    "                                                x=column_names, y=column_names))\n",
    "    fig_directional.update_layout(title=f'Directional Difference between Rolling Correlation Matrices of Assets Log Returns, {span} freq periods.',\n",
    "                                  xaxis_title='Assets', yaxis_title='Assets',\n",
    "                                  plot_bgcolor='white',  paper_bgcolor='white')\n",
    "    # Customizing the colorbar tick labels\n",
    "    fig_directional.update_traces(colorbar_tickvals=[-10, -5, 0, 5, 10],\n",
    "                  colorbar_ticktext=['Negative Stronger', 'Negative Weaker', 'UNCH', 'Positive Weaker', 'Positive Stronger'])\n",
    "    \n",
    "    fig_relative.update_layout(\n",
    "    width=900,  # Adjust width\n",
    "    height=900,  # Adjust height\n",
    "    title=f'Relative Range Percentage Change of Rolling Correlations between Assets Log Returns, {span} freq periods.',\n",
    "    xaxis_title='Assets',\n",
    "    yaxis_title='Assets',\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white',\n",
    "    xaxis={'autorange': True, 'tickangle': 45},  # Rotate x-axis labels to prevent overlap\n",
    "    yaxis={'autorange': True}\n",
    "    )\n",
    "\n",
    "    fig_directional.update_layout(\n",
    "        width=900,  # Adjust width\n",
    "        height=900,  # Adjust height\n",
    "        title=f'Directional Difference between Rolling Correlation Matrices of Assets Log Returns, {span} freq periods.',\n",
    "        xaxis_title='Assets',\n",
    "        yaxis_title='Assets',\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        xaxis={'autorange': True, 'tickangle': 45},  # Rotate x-axis labels to prevent overlap\n",
    "        yaxis={'autorange': True}\n",
    "    )\n",
    "    return fig_relative, fig_directional\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_net(df, ref_date, corr_threshold, span):\n",
    "    global dict_classes\n",
    "    corr_matrix = rolling_corr(df, ref_date, span)\n",
    "    \n",
    "    # Initialize the graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Ticker categories and their colors\n",
    "    ticker_categs = dict_classes\n",
    "    \n",
    "    colors = {\n",
    "        'Equity': 'yellow',\n",
    "        'Index': 'blue',\n",
    "        'Fixed Income': 'red',\n",
    "        'Commodities': 'orange',\n",
    "        'Crypto': 'green'\n",
    "    }\n",
    "    \n",
    "    # Node colors based on their category\n",
    "    node_colors = {}\n",
    "    for category, nodes in ticker_categs.items():\n",
    "        for node in nodes:\n",
    "            node_colors[node] = colors[category]\n",
    "    \n",
    "    # Determine which nodes should be included based on the correlation threshold\n",
    "    nodes_to_include = set()\n",
    "    for i in corr_matrix.columns:\n",
    "        for j in corr_matrix.columns:\n",
    "            if i != j and abs(corr_matrix.loc[i, j]) > corr_threshold:\n",
    "                nodes_to_include.add(i)\n",
    "                nodes_to_include.add(j)\n",
    "    \n",
    "    # Only add nodes that are part of an edge meeting the threshold\n",
    "    for node in nodes_to_include:\n",
    "        G.add_node(node, color=node_colors.get(node, 'grey'))\n",
    "    \n",
    "    # Add edges to the graph based on correlation\n",
    "    for i in corr_matrix.columns:\n",
    "        for j in corr_matrix.columns:\n",
    "            if i != j:  # Ensure we don't compare the same stock to itself\n",
    "                corr = corr_matrix.loc[i, j]\n",
    "                if abs(corr) > corr_threshold:  # Check if the correlation meets the threshold\n",
    "                    # Add an edge with color based on the sign of the correlation\n",
    "                    G.add_edge(i, j, weight=corr, color='green' if corr > 0 else 'red')\n",
    "\n",
    "    # Assuming 'G' is your original graph with 'weight' attributes holding the correlations\n",
    "    H = G.copy()\n",
    "\n",
    "    # Update edge weights in H to be absolute values of the original weights\n",
    "    for u, v, d in H.edges(data=True):\n",
    "        d['weight'] = abs(d['weight'])\n",
    "\n",
    "\n",
    "    # Assuming H is your graph for layout and G contains original correlation weights\n",
    "    pos = nx.kamada_kawai_layout(H)                    \n",
    "    \n",
    "\n",
    "    # Initialize the figure once, before the loop\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # For edges, create individual traces within the loop\n",
    "    for edge in G.edges(data=True):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        corr_value = edge[2]['weight']\n",
    "\n",
    "        # Determine the color based on the correlation value\n",
    "        edge_color = 'green' if corr_value > 0 else 'red'\n",
    "\n",
    "        # Create an individual trace for this edge\n",
    "        edge_trace = go.Scatter(\n",
    "            x=[x0, x1, None], \n",
    "            y=[y0, y1, None],\n",
    "            line=dict(width=0.5, color=edge_color),\n",
    "            mode='lines',\n",
    "            hoverinfo='none',\n",
    "            showlegend=False# No hover info for the line itself\n",
    "        )\n",
    "        fig.add_trace(edge_trace)\n",
    "\n",
    "        # Invisible marker at the midpoint for hover text\n",
    "        midpoint_trace = go.Scatter(\n",
    "            x=[(x0 + x1) / 2],\n",
    "            y=[(y0 + y1) / 2],\n",
    "            text=[f'{edge[0]}-{edge[1]}: {corr_value:.2f}'],\n",
    "            mode='markers',\n",
    "            hoverinfo='text',\n",
    "            marker=dict(size=0.1, color='rgba(0,0,0,0)'),  # Make the marker virtually invisible\n",
    "            showlegend=False\n",
    "        )\n",
    "        fig.add_trace(midpoint_trace)\n",
    "\n",
    "        \n",
    "    # Track which categories have been added to the legend\n",
    "    added_categories = set()\n",
    "    for node in G.nodes():\n",
    "        x, y = pos[node]\n",
    "        category = None\n",
    "        for categ, members in ticker_categs.items():\n",
    "            if node in members:\n",
    "                category = categ\n",
    "                break\n",
    "        if category and category not in added_categories:\n",
    "            # Add a representative node for this category to the legend\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[x], y=[y],\n",
    "                mode='markers+text',\n",
    "                marker=dict(color=colors[category], size=10),\n",
    "                name=category,  # This sets the legend entry,\n",
    "                hoverinfo='none'\n",
    "            ))\n",
    "            added_categories.add(category)\n",
    "\n",
    "    # Add node trace after all edge traces have been added\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    node_marker_colors = []\n",
    "\n",
    "    for node in G.nodes():\n",
    "        x, y = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        node_text.append(node)\n",
    "        node_marker_colors.append(G.nodes[node]['color'])\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x, y=node_y, text=node_text, mode='markers+text', hoverinfo='none',\n",
    "        marker=dict(showscale=False, color=node_marker_colors, size=20, line_width=2),\n",
    "        textposition=\"bottom center\", showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.add_trace(node_trace)\n",
    "\n",
    "    # Set the layout for the figure\n",
    "    fig.update_layout(\n",
    "        showlegend=True,\n",
    "        hovermode='closest',\n",
    "        margin=dict(b=0,l=0,r=0,t=0),\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        legend_title_text='Node Categories',\n",
    "        legend=dict(x=1, y=0, xanchor='right', yanchor='bottom')\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APP LAYOUT SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "external_stylesheets = [dbc.themes.BOOTSTRAP]\n",
    "\n",
    "app = Dash(__name__,\n",
    "           external_stylesheets=external_stylesheets,\n",
    "           suppress_callback_exceptions=True,  \n",
    "           prevent_initial_callbacks=True) \n",
    "\n",
    "\n",
    "#Creating navigation bar : \n",
    "navbar = dbc.NavbarSimple(\n",
    "    children=[\n",
    "        dbc.NavItem(dbc.NavLink(\"Home\", href=\"/\")),\n",
    "        dbc.NavItem(dbc.NavLink(\"Analytics\", href=\"/analytics\")),\n",
    "    ],\n",
    "    brand=\"Demo App\",\n",
    "    brand_href=\"/\",\n",
    "    color=\"primary\",\n",
    "    dark=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Define the app layout with different pages\n",
    "app.layout = html.Div([\n",
    "    dcc.Store(id='session-data'),\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "    navbar,\n",
    "    html.Div(id='page-content'), \n",
    "])\n",
    "\n",
    "@app.callback(Output('page-content', 'children'),\n",
    "              [Input('url', 'pathname')])\n",
    "def display_page(pathname):\n",
    "    if pathname == '/analytics':\n",
    "        return layout_analytics\n",
    "    elif pathname == '/':\n",
    "        return layout_home\n",
    "    else:\n",
    "        return html.Div([\n",
    "            html.H1('404 Error'),\n",
    "            html.P('Page not found: the pathname was {}'.format(pathname))\n",
    "        ], style={'textAlign': 'center'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAYOUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import dcc, html\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "layout_home = html.Div([\n",
    "#     dcc.Store(id='session-data', data={})\n",
    "    dbc.Container([\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div([\n",
    "                html.H3(\"Enter Stock Ticker:\", style={'textAlign': 'center'}),\n",
    "                dbc.Input(id='ticker-input', placeholder='Enter ticker, e.g., AAPL', type='text', value='AAPL', style={'margin': '10px 0'})\n",
    "            ], style={'backgroundColor': 'white', 'padding': '20px', 'borderRadius': '5px', 'boxShadow': '0 4px 8px 0 rgba(0, 0, 0, 0.2)'}), width=12)\n",
    "        ], justify='center', className=\"mb-4\", style={'paddingTop': '50px'}),\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col(dbc.Input(id='start-date-input', placeholder='Start Date (YYYY-MM-DD)', type='text', value='2020-12-31'), width=4),\n",
    "            dbc.Col(dbc.Input(id='end-date-input', placeholder='End Date (YYYY-MM-DD)', type='text', value='2023-12-31'), width=4)\n",
    "        ], justify='center', className=\"mb-4\"),\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Dropdown(id='asset-class-dropdown', \n",
    "                                 options=[\n",
    "                                     {'label': 'Equity', 'value': 'Equity'},\n",
    "                                     {'label': 'Forex', 'value': 'Forex'},\n",
    "                                     {'label': 'Fixed Income', 'value': 'Fixed Income'},\n",
    "                                     {'label': 'Commodities', 'value': 'Commodities'}\n",
    "                                 ],\n",
    "                                 placeholder=\"Select asset class\",\n",
    "                                 value=\"Equity\",\n",
    "                                ), width=4),\n",
    "            dbc.Col(dcc.Dropdown(id='sector-dropdown',\n",
    "                                 placeholder=\"Select sector\",\n",
    "                                 value=\"Technology\"\n",
    "                                ), width=4)\n",
    "        ], justify='center', className=\"mb-3\"),\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Checkbox(id='scale-checkbox', className='form-check-input'),\n",
    "                html.Label('Scaled', htmlFor='scale-checkbox', className='form-check-label', style={'margin-left': '10px'})\n",
    "            ], width=3, align='start'),\n",
    "            dbc.Col(dbc.Button('Download Data', id='submit-button', color='danger', n_clicks=0, className='btn-lg'), width=3, align='center'),\n",
    "            dbc.Col(dbc.Button('Reset Data', id='reset-button', color='primary', n_clicks=0, className='btn-lg'), width=3, align='end')\n",
    "        ], justify='center', className=\"mb-3\"),\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div(id='output-container', style={'color': 'white'}), width=12)\n",
    "        ], justify='center', className=\"mb-3\")\n",
    "    ], style={'height': '100vh', 'backgroundColor': '#000000', 'color': 'white'})\n",
    "], style={'backgroundColor': '#000000'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import dcc, html\n",
    "\n",
    "layout_analytics = html.Div([\n",
    "    html.H1(\"Directional Momentum Visualization\", style={'textAlign': 'center'}),\n",
    "    html.H2(\"Network Graph Visualization\", style={'textAlign': 'center'}),\n",
    "    dcc.Store(id='session-data'),\n",
    "#     dcc.Store(id='store-corr-threshold', storage_type='session'),  \n",
    "#     dcc.Store(id='store-span', storage_type='session'),  \n",
    "#     dcc.Store(id='store-selected-date', storage_type='session'),\n",
    "#     dcc.Store(id='net-graph', storage_type='session'),\n",
    "#     dcc.Store(id='heatmap-relative', storage_type='session'),\n",
    "#     dcc.Store(id='heatmap-directional', storage_type='session'),\n",
    "    dcc.Store(id='session-analytics-input'),\n",
    "    dcc.Store(id='session-graphs-analytics'),\n",
    "\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label(\"Correlation Threshold\", style={'textAlign': 'center'}),\n",
    "            dcc.Slider(\n",
    "                id='corr-threshold-slider',\n",
    "                min=0,\n",
    "                max=1,\n",
    "                step=0.01,\n",
    "                value=0.5,  # Default value\n",
    "                marks={str(i/10): str(i / 10) for i in range(0, 11)}, \n",
    "            )\n",
    "        ], style={'width': '30%', 'display': 'inline-block', 'padding': '20px'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Span\", style={'textAlign': 'center'}),\n",
    "            dcc.Input(\n",
    "                id='span-input',\n",
    "                type='number',\n",
    "                value=5,  \n",
    "                min=1,  \n",
    "                max=100,  \n",
    "                step=1  \n",
    "            )\n",
    "        ], style={'width': '15%', 'display': 'inline-block', 'padding': '20px'}),\n",
    "\n",
    "        html.Div([\n",
    "            dcc.DatePickerSingle(\n",
    "                id='date-picker',\n",
    "                min_date_allowed='start',\n",
    "                max_date_allowed='end',\n",
    "                initial_visible_month='start',\n",
    "                date=str('start')  # Set initial date\n",
    "            )\n",
    "        ], style={'width': '30%', 'display': 'inline-block', 'textAlign': 'right', 'float': 'right', 'padding': '20px'}),\n",
    "    ], style={'display': 'flex', 'justifyContent': 'space-between'}),\n",
    "    \n",
    "\n",
    "    dcc.Graph(id='network-graph'),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.H2(\"Heatmap, Relative\", style={'textAlign': 'center'}),\n",
    "            dcc.Graph(id='heatmap-relative'),\n",
    "        ], style={'width': '50%', 'display': 'inline-block'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.H2(\"Heatmap, Directional\", style={'textAlign': 'center'}),\n",
    "            dcc.Graph(id='heatmap-directional'),\n",
    "        ], style={'width': '50%', 'display': 'inline-block'}),\n",
    "    ], style={'display': 'flex'}),  # This container will hold both heatmaps side by side\n",
    "    \n",
    "    html.Div(id='error-message', style={'color': 'red', 'fontWeight': 'bold'})  # Error message div\n",
    "], style={'padding': '20px'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_portfolio = html.Div([\n",
    "    html.H1('Portfolio Page'),\n",
    "    # Further components and layout details for the Home page\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALLBACKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    [Output('output-container', 'children'),\n",
    "     Output('session-data', 'data')],\n",
    "    [Input('submit-button', 'n_clicks'),\n",
    "     Input('reset-button', 'n_clicks'),\n",
    "     Input('scale-checkbox', 'value'),\n",
    "     Input('url', 'pathname')],  # Listen to URL changes\n",
    "    [State('ticker-input', 'value'),\n",
    "     State('asset-class-dropdown', 'value'),\n",
    "     State('sector-dropdown', 'value'),\n",
    "     State('start-date-input', 'value'),\n",
    "     State('end-date-input', 'value'), \n",
    "     State('session-data', 'data')]\n",
    ")\n",
    "def update_or_reload_data(submit_n_clicks, reset_n_clicks, scale, pathname,\n",
    "                          ticker, asset_class, asset_sector, start_date, end_date, session_data):\n",
    "    global main_df\n",
    "    global initializer\n",
    "    global list_tickers, dict_classes, dict_sectors, dict_commo\n",
    "    key = 0\n",
    "    triggered_id = callback_context.triggered[0]['prop_id'].split('.')[0]\n",
    "    session_data = session_data or {'Price Plot': None, 'start': start_date, 'end': end_date, 'scale': scale}\n",
    "\n",
    "\n",
    "    if initializer:\n",
    "        initializer = False\n",
    "        return html.Div(\"Empty Graph Data\"), {'Price Plot' : None, 'start' : None, 'end' : None, 'scale' : False}\n",
    "    \n",
    "    if triggered_id == 'reset-button' and reset_n_clicks > 0:\n",
    "        main_df = pd.DataFrame()\n",
    "        reset_global_vars()\n",
    "        return html.Div(\"Data has been reset\"), {'Price Plot' : None, 'start' : None, 'end' : None, 'scale' : False}\n",
    "    \n",
    "    json_dump = None\n",
    "    if triggered_id == 'submit-button' or triggered_id == 'scale-checkbox':\n",
    "        try:\n",
    "            df = data_loader(ticker, start=start_date, end=end_date)\n",
    "            df.dropna(inplace=True)\n",
    "            if df.empty:\n",
    "                return html.Div(\"No data available for the selected ticker and date range.\"), {'Price Plot' : None, 'start' : None, 'end' : None, 'scale' : False}\n",
    "\n",
    "            if main_df.empty:\n",
    "                main_df = df\n",
    "            else:\n",
    "                prefix = ticker\n",
    "                matching_columns = [col for col in main_df.columns if col.startswith(prefix)]\n",
    "                main_df.drop(columns=matching_columns, inplace=True)\n",
    "                main_df = pd.merge(main_df, df, left_index=True, right_index=True, how='inner')\n",
    "        except Exception as e:\n",
    "            return html.Div(f\"Failed to load data for {ticker}: {str(e)}\"), {'Price Plot' : None, 'start' : None, 'end' : None, 'scale' : False}  \n",
    "    \n",
    "    elif session_data:\n",
    "        if 'Price Plot' in session_data and session_data['Price Plot']:\n",
    "            json_str = session_data['Price Plot']\n",
    "            try:\n",
    "                json_dump = pd.read_json(json_str, orient='split')\n",
    "                key = 1 \n",
    "            except ValueError as e:\n",
    "                print(\"Error loading JSON data:\", e)\n",
    "                return html.Div(\"Failed to load data.\"), {'Price Plot': None, 'start': None, 'end': None, 'scale' : False}\n",
    "\n",
    "            \n",
    "    #Select subset of main_df \n",
    "    sub_df = prepare_and_scale_df(main_df, json_dump, key, scale)\n",
    "    \n",
    "    fig = plot_fig(sub_df)\n",
    "\n",
    "\n",
    "    start_time = dt.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    end_time = dt.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "    #UPDATE TO GLOBAL VARIABLES\n",
    "    list_tickers.append(ticker)\n",
    "    list_tickers = list(set(list_tickers))\n",
    "\n",
    "    dict_classes[asset_class].append(ticker)\n",
    "    dict_classes[asset_class] = list(set(dict_classes[asset_class]))\n",
    "\n",
    "    if asset_class == 'Commodities':\n",
    "        dict_commo[asset_sector].append(ticker)\n",
    "        dict_commo[asset_sector] = list(set(dict_commo[asset_sector]))\n",
    "    if asset_class == 'Equity':\n",
    "        dict_sectors[asset_sector].append(ticker)\n",
    "        dict_sectors[asset_sector] = list(set(dict_sectors[asset_sector]))\n",
    "\n",
    "    return dcc.Graph(figure=fig), {'Price Plot' : sub_df.to_json(date_format='iso', orient='split'), \n",
    "                                   'start' : start_time, \n",
    "                                   'end' : end_time, \n",
    "                                   'scale' : scale}\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('sector-dropdown', 'options'),\n",
    "    [Input('asset-class-dropdown', 'value')]\n",
    ")\n",
    "def set_sectors_options(selected_asset_class):\n",
    "    if selected_asset_class == 'Equity':\n",
    "        return [{'label': 'Technology', 'value': 'Technology'},\n",
    "                {'label': 'Consumer', 'value': 'Consumer'},\n",
    "                {'label': 'Utilities', 'value': 'Uitilies'},\n",
    "                {'label': 'Industrial', 'value': 'Consumer'},\n",
    "                {'label': 'Financials', 'value': 'Financials'},\n",
    "                {'label': 'Other', 'value': 'Other'},]\n",
    "    elif selected_asset_class == 'Commodities':\n",
    "        return [{'label': 'Agriculture', 'value': 'Agriculture'},\n",
    "                {'label': 'Precious Metals', 'value': 'Precious Metals'},\n",
    "                {'label': 'Industrials', 'value': 'Industrials'},\n",
    "                {'label': 'Energy', 'value': 'Energy'}]\n",
    "    else:\n",
    "        return [{'label' : 'N/A', 'value' : 'N/A'}]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('span-input', 'value'),\n",
    "    [Input('date-picker', 'date'),\n",
    "     Input('span-input', 'value')]\n",
    ")\n",
    "def debugging(ref_date, span):\n",
    "    \n",
    "    #First : Check if Span input is indeed a positive int\n",
    "    assert isinstance(span, int)\n",
    "    assert span >= 0, \"span must be a positive integer\"\n",
    "    \n",
    "    #Second : Debugging the Ref_Date \n",
    "    if ref_date not in main_df.index:\n",
    "        print('Ref_date not in df.index')\n",
    "        ref_date = main_df.index[0]\n",
    "    else: \n",
    "        ref_date = ref_date \n",
    "    \n",
    "    #Third : Debugging the Span  \n",
    "    #Retrieve position of the current date\n",
    "    position = main_df.index.get_loc(ref_date) + 1\n",
    "    if 2*span > position: #because we need 2 periods of length span \n",
    "        print('Span too high compared to index position. Rescaling')\n",
    "        span = position // 2\n",
    "\n",
    "    print(f'Select position : {main_df.index[span]} minimum for a span window of {span}.')\n",
    "\n",
    "    return span\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [Output('network-graph', 'figure'),\n",
    "     Output('heatmap-relative', 'figure'),\n",
    "     Output('heatmap-directional', 'figure'),\n",
    "     Output('error-message', 'children'),\n",
    "     Output('session-analytics-input', 'data'),\n",
    "     Output('session-analytics-graph', 'data')],\n",
    "    [Input('date-picker', 'date'),\n",
    "     Input('corr-threshold-slider', 'value'), \n",
    "     Input('span-input', 'value')]\n",
    ")\n",
    "def update_graph(selected_date, corr_threshold, span):\n",
    "    global main_df\n",
    "    \n",
    "    #Only selecting the columns which are named as \"Ticker : Log-Returns\" from main_df\n",
    "    suffix = 'Log-Returns'\n",
    "    subset_cols = [col for col in list(main_df.columns) if col.endswith(suffix)]\n",
    "    subset_df = main_df[subset_cols]\n",
    "    subset_df.columns = list_tickers\n",
    "    \n",
    "    \n",
    "    span = debugging(selected_date, span)\n",
    "\n",
    "    corr_result = rolling_corr(subset_df, selected_date, span)  \n",
    "    if isinstance(corr_result, str) and corr_result == \"Date not found\":\n",
    "        inputs = {'Corr' : 0, \n",
    "                  'Date' : subset_df.index[0], \n",
    "                  'Span' : 0}\n",
    "        graphs = {'NetGraph' : None,\n",
    "                  'HeatMapRel' : None, \n",
    "                  'HeatMapDir' : None}\n",
    "        error_msg = \"Error: Selected date not found in the dataset.\"\n",
    "        return dash.no_update, dash.no_update, dash.no_update, error_msg, inputs, graphs\n",
    "    else:\n",
    "        try: \n",
    "            network_fig = graph_net(subset_df, selected_date, corr_threshold=corr_threshold, span=span)\n",
    "            heatmap_relative_graph, heatmap_directional_graph = rolling_corr_difference(subset_df, selected_date, span=span)\n",
    "\n",
    "            inputs = {'Corr' : corr_threshold, \n",
    "                      'Date' : selected_date, \n",
    "                      'Span' : span}\n",
    "            graphs = {'NetGraph' : network_fig,\n",
    "                      'HeatMapRel' : heatmap_relative_graph, \n",
    "                      'HeatMapDir' : heatmap_directional_graph}\n",
    "            error_msg = \"\"\n",
    "            return network_fig, heatmap_relative_graph, heatmap_directional_graph, error_msg, inputs, graphs\n",
    "\n",
    "        except Exception as e:\n",
    "            inputs = {'Corr' : 0, \n",
    "                      'Date' : subset_df.index[0], \n",
    "                      'Span' : 0}\n",
    "            graphs = {'NetGraph' : None,\n",
    "                      'HeatMapRel' : None, \n",
    "                      'HeatMapDir' : None}\n",
    "            error_msg = f\"Error: {str(e)}\"\n",
    "            return dash.no_update, dash.no_update, dash.no_update, error_msg, inputs, graphs\n",
    "\n",
    "    \n",
    "#     if selected_date is not None and corr_threshold is not None:\n",
    "#         # Check if selected_date is valid using rolling_corr or equivalent function\n",
    "#         corr_result = rolling_corr(subset_df, selected_date, span)  \n",
    "#         if isinstance(corr_result, str) and corr_result == \"Date not found\":\n",
    "#             inputs = {'Corr' : 0, \n",
    "#                       'Date' : subset_df.index[0], \n",
    "#                       'Span' : 0}\n",
    "#             graphs = {'NetGraph' : None,\n",
    "#                       'HeatMapRel' : None, \n",
    "#                       'HeatMapDir' : None}\n",
    "#             error_msg = \"Error: Selected date not found in the dataset.\"\n",
    "#             return dash.no_update, dash.no_update, dash.no_update, error_msg, inputs, graphs\n",
    "#         else:\n",
    "#             try: \n",
    "#                 network_fig = graph_net(subset_df, selected_date, corr_threshold=corr_threshold, span=span)\n",
    "#                 heatmap_relative_graph, heatmap_directional_graph = rolling_corr_difference(subset_df, selected_date, span=span)\n",
    "                \n",
    "#                 inputs = {'Corr' : corr_threshold, \n",
    "#                           'Date' : selected_date, \n",
    "#                           'Span' : span}\n",
    "#                 graphs = {'NetGraph' : network_fig,\n",
    "#                           'HeatMapRel' : heatmap_relative_graph, \n",
    "#                           'HeatMapDir' : heatmap_directional_graph}\n",
    "#                 error_msg = \"\"\n",
    "#                 return network_fig, heatmap_relative_graph, heatmap_directional_graph, error_msg, inputs, graphs\n",
    "            \n",
    "#             except Exception as e:\n",
    "#                 inputs = {'Corr' : 0, \n",
    "#                           'Date' : subset_df.index[0], \n",
    "#                           'Span' : 0}\n",
    "#                 graphs = {'NetGraph' : None,\n",
    "#                           'HeatMapRel' : None, \n",
    "#                           'HeatMapDir' : None}\n",
    "#                 error_msg = f\"Error: {str(e)}\"\n",
    "#                 return dash.no_update, dash.no_update, dash.no_update, error_msg, inputs, graphs\n",
    "#     else:\n",
    "#         inputs = {'Corr' : 0, \n",
    "#                   'Date' : subset_df.index[0], \n",
    "#                   'Span' : 0}\n",
    "#         graphs = {'NetGraph' : None,\n",
    "#                   'HeatMapRel' : None, \n",
    "#                   'HeatMapDir' : None}\n",
    "#         error_msg = \"\"\n",
    "#         return dash.no_update, dash.no_update, dash.no_update, error_msg, inputs, graphs\n",
    "\n",
    "    \n",
    "@app.callback(\n",
    "    [Output('date-picker', 'min_date_allowed'),\n",
    "     Output('date-picker', 'max_date_allowed'),\n",
    "     Output('date-picker', 'initial_visible_month'),\n",
    "     Output('date-picker', 'date')],\n",
    "    [Input('session-data', 'data')],\n",
    ")\n",
    "def update_date_picker(session_data):\n",
    "    if session_data:\n",
    "        min_date = session_data.get('start')\n",
    "        max_date = session_data.get('end')\n",
    "        return min_date, max_date, min_date, min_date\n",
    "    # Default to some range if no data is found\n",
    "    default_date = datetime.datetime.today().date()\n",
    "    return default_date, default_date, default_date, default_date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8008/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7face5f5f9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "# Run the app\n",
    "port = 8008\n",
    "\n",
    "# Open a web browser tab using the specified port\n",
    "def open_browser():\n",
    "      webbrowser.open_new_tab(f'http://127.0.0.1:{port}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Use the threading module to open a web browser tab\n",
    "    # This prevents blocking the execution of the app\n",
    "    from threading import Timer\n",
    "    Timer(1, open_browser).start()  # Wait 1 second before opening the tab\n",
    "    \n",
    "    app.run_server(debug=True, port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
